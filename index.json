[{"content":"","date":"18 September 2023","permalink":"/basic/","section":"Basics","summary":"","title":"Basics"},{"content":"HTTP 相关技术\n1.HTTP / 1.1 # 1.1 HTTP/1.1 的优点 # HTTP 最突出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。\n1. 简单\nHTTP 基本的报文格式就是 header + body，头部信息也是 key-value 简单文本的形式，易于理解，降低了学习和使用的门槛。\n2. 灵活和易于扩展\nHTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充。\n同时 HTTP 由于是工作在应用层（ OSI 第七层），则它下层可以随意变化，比如：\nHTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层； HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。 3. 应用广泛和跨平台\n互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有跨平台的优越性。\n1.2 HTTP/1.1 的缺点 # HTTP 协议里有优缺点一体的双刃剑，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。\n1. 无状态\n无状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。\n无状态的坏处，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。\n对于无状态的问题，解法方案有很多种，其中比较简单的方式用 Cookie 技术。\nCookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。\n相当于，在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了。\n2. 明文传输\n明文意味着在传输过程中的信息，是可方便阅读的，比如 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。\n但是这正是这样，HTTP 的所有信息都容易被窃取。\n3. 不安全\nHTTP 比较严重的缺点就是不安全：\n通信使用明文（不加密），内容可能会被窃听。 不验证通信方的身份，因此有可能遭遇伪装。 无法证明报文的完整性，所以有可能已遭篡改。 HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。\n1.3 HTTP/1.1 的性能 # HTTP 协议是基于 TCP/IP，并且使用了「请求 - 应答」的通信模式，所以性能的关键就在这两点里。\n1. 长连接\n早期 HTTP/1.0 性能上的一个很大的问题，那就是每发起一个请求，都要新建一次 TCP 连接（三次握手），而且是串行请求，做了无谓的 TCP 连接建立和断开，增加了通信开销。\n为了解决上述 TCP 连接问题，HTTP/1.1 提出了长连接的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。\n持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。\n当然，如果某个 HTTP 长连接超过一定时间没有任何数据交互，服务端就会主动断开这个连接。\n2. 管道网络传输\nHTTP/1.1 采用了长连接的方式，这使得管道（pipeline）网络传输成为了可能。\n即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。\n举例来说，客户端需要请求两个资源。以前的做法是，在同一个 TCP 连接里面，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。那么，管道机制则是允许浏览器同时发出 A 请求和 B 请求。\n但是服务器必须按照接收请求的顺序发送对这些管道化请求的响应。\n如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为「队头堵塞」。\n所以，HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞。\n3. 队头阻塞\n「请求 - 应答」的模式会造成 HTTP 的性能问题。\n因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「队头阻塞」，好比上班的路上塞车。\n总之 HTTP/1.1 的性能一般般，后续的 HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。\n2.HTTP 与 HTTPS # 2.1 HTTP 与 HTTPS 区别 # HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。 HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。 HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。 2.2 HTTPS 解决了 HTTP 的哪些问题 # 窃听风险，比如通信链路上可以获取通信内容。 篡改风险，比如强制植入垃圾广告，视觉污染。 冒充风险，比如冒充淘宝网站。 HTTPS 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，可以很好的解决了上述的风险：\n信息加密：交互信息无法被窃取。 校验机制：无法篡改通信内容，篡改了就不能正常显示。 身份证书：证明淘宝是真的淘宝网。 HTTPS 是如何解决上面的三个风险的：\n混合加密的方式实现信息的机密性，解决了窃听的风险。 摘要算法的方式来实现完整性，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。 将服务器公钥放入到数字证书中，解决了冒充的风险。 2.3 HTTPS 是如何建立连接（四次握手） # SSL/TLS 协议基本流程：\n客户端向服务器索要并验证服务器的公钥。 双方协商生产「会话秘钥」。 双方采用「会话秘钥」进行加密通信。 前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。\nTLS 的「握手阶段」涉及四次通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：RSA 算法 和 ECDHE 算法。\nTLS 协议建立的详细流程：\n1. ClientHello\n首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。\n客户端主要向服务器发送以下信息：\n（1）客户端支持的 TLS 协议版本，如 TLS 1.2 版本。\n（2）客户端生产的随机数（Client Random），后面用于生成「会话秘钥」条件之一。\n（3）客户端支持的密码套件列表，如 RSA 加密算法。\n2. SeverHello\n服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。服务器回应的内容有如下内容：\n（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。\n（2）服务器生产的随机数（Server Random），也是后面用于生产「会话秘钥」条件之一。\n（3）确认的密码套件列表，如 RSA 加密算法。\n（4）服务器的数字证书。\n3.客户端回应\n客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。\n如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送：\n（1）一个随机数（pre-master key）。该随机数会被服务器公钥加密。\n（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。\n（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。\n上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。\n服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。\n4. 服务器的最后回应\n服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。\n然后，向客户端发送最后的信息：\n（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。\n（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。\n至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。\n2.4 数字证书签发和验证流程 # CA 签发证书的过程：\n首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值； 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名； 最后将 Certificate Signature 添加在文件证书上，形成数字证书； 客户端校验服务端的数字证书的过程，如上图右边部分：\n首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1； 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ； 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。 2.5 HTTPS 的应用数据是如何保证完整性的 # TLS 在实现上分为握手协议和记录协议两层：\nTLS 握手协议负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）； TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议； TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证，过程如下图：\n具体过程如下：\n首先，消息被分割成多个较短的片段,然后分别对每个片段进行压缩。 接下来，经过压缩的片段会被加上消息认证码（MAC 值，这个是通过哈希算法生成的），这是为了保证完整性，并进行数据的认证。通过附加消息认证码的 MAC 值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码。 再接下来，经过压缩的片段再加上消息认证码会一起通过对称密码进行加密。 最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。 记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输。\n2.6 中间人服务器 # 客户端通过浏览器向服务端发起 HTTPS 请求时，被「假基站」转发到了一个「中间人服务器」，于是客户端是和「中间人服务器」完成了 TLS 握手，然后这个「中间人服务器」再与真正的服务端完成 TLS 握手。\n具体过程如下：\n客户端向服务端发起 HTTPS 建立连接请求时，然后被「假基站」转发到了一个「中间人服务器」，接着中间人向服务端发起 HTTPS 建立连接请求，此时客户端与中间人进行 TLS 握手，中间人与服务端进行 TLS 握手； 在客户端与中间人进行 TLS 握手过程中，中间人会发送自己的公钥证书给客户端，客户端验证证书的真伪，然后从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给中间人，中间人使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（A），后续客户端与中间人通信就用这个对称加密密钥来加密数据了。 在中间人与服务端进行 TLS 握手过程中，服务端会发送从 CA 机构签发的公钥证书给中间人，从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给服务端，服务端使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（B），后续中间人与服务端通信就用这个对称加密密钥来加密数据了。 后续的通信过程中，中间人用对称加密密钥（A）解密客户端的 HTTPS 请求的数据，然后用对称加密密钥（B）加密 HTTPS 请求后，转发给服务端，接着服务端发送 HTTPS 响应数据给中间人，中间人用对称加密密钥（B）解密 HTTPS 响应数据，然后再用对称加密密钥（A）加密后，转发给客户端。 从客户端的角度看，其实并不知道网络中存在中间人服务器这个角色。那么中间人就可以解开浏览器发起的 HTTPS 请求里的数据，也可以解开服务端响应给浏览器的 HTTPS 响应数据。相当于，中间人能够 “偷看” 浏览器与服务端之间的 HTTPS 请求和响应的数据。\n但是要发生这种场景是有前提的，前提是用户点击接受了中间人服务器的证书。\n中间人服务器与客户端在 TLS 握手过程中，实际上发送了自己伪造的证书给浏览器，而这个伪造的证书是能被浏览器（客户端）识别出是非法的，于是就会提醒用户该证书存在问题。\n所以，HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全。\n2.7 如何避免中间人攻击 # 为什么抓包工具能截取 HTTPS 数据？\n很多抓包工具 之所以可以明文看到 HTTPS 数据，工作原理与中间人一致的。\n对于 HTTPS 连接来说，中间人要满足以下两点，才能实现真正的明文代理:\n中间人，作为客户端与真实服务端建立连接这一步不会有问题，因为服务端不会校验客户端的身份； 中间人，作为服务端与真实客户端建立连接，这里会有客户端信任服务端的问题，也就是服务端必须有对应域名的私钥； 中间人要拿到私钥只能通过如下方式：\n去网站服务端拿到私钥； 去CA处拿域名签发私钥； 自己签发证书，切要被浏览器信任； 不用解释，抓包工具只能使用第三种方式取得中间人的身份。\n使用抓包工具进行 HTTPS 抓包的时候，需要在客户端安装 Fiddler 的根证书，这里实际上起认证中心（CA）的作用。\n抓包工具能够抓包的关键是客户端会往系统受信任的根证书列表中导入抓包工具生成的证书，而这个证书会被浏览器信任，也就是抓包工具给自己创建了一个认证中心 CA，客户端拿着中间人签发的证书去中间人自己的 CA 去认证，当然认为这个证书是有效的。\n如何避免被中间人抓取数据？\n我们要保证自己电脑的安全，不要被病毒乘虚而入，而且也不要点击任何证书非法的网站，这样 HTTPS 数据就不会被中间人截取到了。\n当然，我们还可以通过 HTTPS 双向认证来避免这种问题。\n一般我们的 HTTPS 是单向认证，客户端只会验证了服务端的身份，但是服务端并不会验证客户端的身份。\n如果用了双向认证方式，不仅客户端会验证服务端的身份，而且服务端也会验证客户端的身份。服务端一旦验证到请求自己的客户端为不可信任的，服务端就拒绝继续通信，客户端如果发现服务端为不可信任的，那么也中止通信。\n3.HTTP/1.1、HTTP/2、HTTP/3 演变 # 3.1 HTTP/1.1 相比 HTTP/1.0 提高了什么性能 # HTTP/1.1 相比 HTTP/1.0 性能上的改进：\n使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。 但 HTTP/1.1 还是有性能瓶颈：\n请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分； 发送冗长的首部。每次互相发送相同的首部造成的浪费较多； 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞； 没有请求优先级控制； 请求只能从客户端开始，服务器只能被动响应。 3.2 HTTP/2 的优化 # HTTP/2 相比 HTTP/1.1 性能上的改进：\n头部压缩：通过HPACK 算法，在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，之后就不发送同样字段了，只发送索引号，可以提高速度。 二进制格式：HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式**，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧（Headers Frame）和数据帧（Data Frame）。 并发传输：HTTP/1.1 的实现是基于请求-响应模型的，可能会出现队头阻塞的情况，而 HTTP/2 针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应。 服务器主动推送资源：HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以主动向客户端发送消息。（客户端和服务器双方都可以建立 Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号）。 3.3 HTTP/3 的优化 # HTTP/2 队头阻塞的问题是因为 TCP，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP，基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输：\n**无队头阻塞：QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。 **更快的连接建立：HTTP/3 在传输数据前虽然需要 QUIC 协议握手，但是这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的 连接迁移：基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，所以当 IP 地址改变就需要断开连接，重新进行建立连接，而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过连接 ID** 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。 4.HTTP 缓存技术 # 4.1 强制缓存 # 指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。\nsize 项中标识的是 from disk cache，就是使用了强制缓存 Cache-Control， 是一个相对时间； Expires，是一个绝对时间； 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control 4.2 协商缓存 # 某些请求的响应码是 304，这个是告诉浏览器可以使用本地缓存的资源，通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存\n协商缓存可以基于两种头部来实现：\n第一种：请求头部中的 If-Modified-Since 字段与响应头部中的 Last-Modified 字段实现，这两个字段的意思是：\n响应头部中的 Last-Modified：标示这个响应资源的最后修改时间； 请求头部中的 If-Modified-Since：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。 第二种：请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段：\n响应头部中 Etag：唯一标识响应资源； 请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。 ","date":"18 September 2023","permalink":"/basic/network/review/02/","section":"Basics","summary":"HTTP 相关技术","title":"HTTP"},{"content":"","date":"18 September 2023","permalink":"/tags/network/","section":"Tags","summary":"","title":"network"},{"content":"","date":"18 September 2023","permalink":"/tags/review/","section":"Tags","summary":"","title":"review"},{"content":"","date":"18 September 2023","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":" 1.TCP 三次握手过程 # 首先客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态 客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序列号」字段中，同时把 SYN 标志位置为 1，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的「序列号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态 服务端收到客户端的应答报文后，也进入 ESTABLISHED 状态 三次握手的原因：\n三次握手才可以阻止重复历史连接的初始化（主要原因）：两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费 三次握手才可以同步双方的初始序列号 三次握手才可以避免资源浪费：如果客户端发送的 SYN 报文在网络中阻塞了，重复发送多次 SYN 报文，那么服务端在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费 2.TCP 四次挥手过程 # 如果客户端打算关闭连接，首先会发送一个 TCP 首部 FIN 标志位被置为 1 的 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSE_WAIT 状态。 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态 服务端收到了 ACK 应答报文后，就进入了 CLOSE 状态，至此服务端已经完成连接的关闭。 客户端在经过 2MSL 一段时间后，自动进入 CLOSE 状态，至此客户端也完成连接的关闭。 3.TCP 和 UDP 区别 # 1. 连接\nTCP 是面向连接的传输层协议，传输数据前先要建立连接。 UDP 是不需要连接，即刻传输数据。 2. 服务对象\nTCP 是一对一的两点服务，即一条连接只有两个端点。 UDP 支持一对一、一对多、多对多的交互通信 3. 可靠性\nTCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。 UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议。 4. 拥塞控制、流量控制\nTCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。 5. 首部开销\nTCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。 6. 传输方式\nTCP 是流式传输，没有边界，但保证顺序和可靠。 UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。 7. 分片不同\nTCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。 TCP 和 UDP 应用场景：\n由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：\nFTP 文件传输； HTTP / HTTPS； 由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：\n包总量较少的通信，如 DNS 、SNMP 等； 视频、音频等多媒体通信； 广播通信。 4.为什么挥手需要四次 # 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。 而服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，所以是需要四次挥手，但是在特定情况下，四次挥手是可以变成三次挥手的。（当被动关闭方在 TCP 挥手过程中，如果「没有数据要发送」，同时「没有开启 TCP_QUICKACK（默认情况就是没有开启，没有开启 TCP_QUICKACK，等于就是在使用 TCP 延迟确认机制）」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。）\n5.重传机制 # **超时重传：数据包丢失、确认应答丢失：**在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据 **快速重传：不以时间为驱动，而是以数据驱动重传：**当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。（存在问题：重传一个，还是重传所有的问题） SACK：选择性确认：在 TCP 头部「选项」字段里加一个 SACK ，可以将已收到的数据的信息发送给「发送方」，这样发送方就可以知道哪些数据收到了，哪些数据没收到，可以只重传丢失的数据。 D-SACK：使用了 SACK 来告诉「发送方」有哪些数据被重复接收。 6.滑动窗口 # 解决了往返时间越长，通信效率越低的问题，窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。（通常窗口的大小是由接收方的窗口大小来决定的，发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据）\n7.流量控制 # 发送方将数据发送给接收方，要考虑接收方处理能力：TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，即流量控制。\n8.拥塞控制 # 因为流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。而计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。拥塞控制的目的是避免「发送方」的数据填满整个网络。\n拥塞控制主要是四个算法：\n慢启动 拥塞避免 拥塞发生：超时重传、快速重传 快速恢复 9.TCP 序列号和确认号 # 发送的 TCP 报文：\n公式一：序列号 = 上一次发送的序列号 + len（数据长度）。特殊情况，如果上一次发送的报文是 SYN 报文或者 FIN 报文，则改为 上一次发送的序列号 + 1。 公式二：确认号 = 上一次收到的报文中的序列号 + len（数据长度）。特殊情况，如果收到的是 SYN 报文或者 FIN 报文，则改为上一次收到的报文中的序列号 + 1。 三个字段的作用：\n序列号：在建立连接时由内核生成的随机数作为其初始值，通过 SYN 报文传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。 确认号：指下一次「期望」收到的数据的序列号，发送端收到接收方发来的 ACK 确认报文以后，就可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。 控制位：用来标识 TCP 报文是什么类型的报文，比如是 SYN 报文、数据报文、ACK 报文，FIN 报文等。 10.TIME_WAIT 的作用 # 防止历史连接中的数据，被后面相同四元组的连接错误的接收 保证「被动关闭连接」的一方，能被正确的关闭 11.TIME_WAIT 过多的危害 # 占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。 占用端口资源，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过 net.ipv4.ip_local_port_range参数指定范围。 12.TIME_WAIT 优化 # 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项（可以复用处于 TIME_WAIT 的 socket 为新的连接所用） net.ipv4.tcp_max_tw_buckets（当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置） 程序中使用 SO_LINGER ，应用强制使用 RST 关闭 13.服务器出现大量 TIME_WAIT 状态的原因 # 首先要知道 TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接，服务端会主动断开连接呢的场景：\nHTTP 没有使用长连接 HTTP 长连接超时 HTTP 长连接的请求数量达到上限 14.TCP 服务端的流程 # 创建服务端 socket，bind 绑定端口、listen 监听端口 将服务端 socket 注册到 epoll epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket 将已连接的 socket 注册到 epoll epoll_wait 等待事件发生 对方连接关闭时，我方调用 close ","date":"18 September 2023","permalink":"/basic/network/review/03/","section":"Basics","summary":"1.","title":"TCP"},{"content":"Less can be more\n","date":"18 September 2023","permalink":"/","section":"Welcome to NewtSun","summary":"Less can be more","title":"Welcome to NewtSun"},{"content":"计算机网络模型的相关基础\n1.TCP/IP 网络模型 # TCP/IP 网络通常是由上到下分成 4 层，分别是应用层，传输层，网络层和网络接口层：\n每一层的封装格式：\n网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。\n2.OSI 网络模型 # 为了使得多种设备能通过网络相互通信，和为了解决各种不同设备在网络互联中的兼容性问题，国际标准化组织制定了开放式系统互联通信参考模型（Open System Interconnection Reference Model），也就是 OSI 网络模型，该模型主要有 7 层，分别是应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层。\n每一层负责的职能都不同，如下：\n应用层，负责给应用程序提供统一的接口； 表示层，负责把数据转换成兼容另一个系统能识别的格式； 会话层，负责建立、管理和终止表示层实体之间的通信会话； 传输层，负责端到端的数据传输； 网络层，负责数据的路由、转发、分片； 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址； 物理层，负责在物理网络中传输数据帧； TCP/IP 网络模型共有 4 层，分别是应用层、传输层、网络层和网络接口层，每一层负责的职能如下：\n应用层，负责向用户提供一组应用程序，比如 HTTP、DNS、FTP 等; 传输层，负责端到端的通信，比如 TCP、UDP 等； 网络层，负责网络包的封装、分片、路由、转发，比如 IP、ICMP 等； 网络接口层，负责网络包在物理网络中的传输，比如网络包的封帧、 MAC 寻址、差错检测，以及通过网卡传输网络帧等； 网络包的报文如下图：\n路由器和交换机是有区别的。\n因为路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址； 而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。 3.Linux 网络协议栈 # 应用层数据在每一层的封装格式：\n其中：\n传输层，给应用数据前面增加了 TCP 头； 网络层，给 TCP 数据包前面增加了 IP 头； 网络接口层，给 IP 数据包前后分别增加了帧头和帧尾； 这些新增的头部和尾部，都有各自的作用，也都是按照特定的协议格式填充，这每一层都增加了各自的协议头，那自然网络包的大小就增大了，但物理链路并不能传输任意大小的数据包，所以在以太网中，规定了最大传输单元（MTU）是 1500 字节，也就是规定了单次传输的最大 IP 包大小。\n当网络包超过 MTU 的大小，就会在网络层分片，以确保分片后的 IP 包不会超过 MTU 大小，如果 MTU 越小，需要的分包就越多，那么网络吞吐能力就越差，相反的，如果 MTU 越大，需要的分包就越少，那么网络吞吐能力就越好。\n知道了 TCP/IP 网络模型，以及网络包的封装原理后，那么 Linux 网络协议栈的样子，你想必猜到了大概，它其实就类似于 TCP/IP 的四层结构：\n从上图的的网络协议栈，可以看到：\n应用程序需要通过系统调用，来跟 Socket 层进行数据交互； Socket 层的下面就是传输层、网络层和网络接口层； 最下面的一层，则是网卡驱动程序和硬件网卡设备； ","date":"18 September 2023","permalink":"/basic/network/review/01/","section":"Basics","summary":"计算机网络模型的相关基础","title":"计算机网络模型基础"},{"content":"","date":"3 September 2023","permalink":"/diary/","section":"Diaries","summary":"","title":"Diaries"},{"content":"","date":"3 September 2023","permalink":"/tags/plan/","section":"Tags","summary":"","title":"Plan"},{"content":"","date":"3 September 2023","permalink":"/tags/todo/","section":"Tags","summary":"","title":"TODO"},{"content":" 1.复习计划： # 计算机网络（9.18） 操作系统（9.19） MySQL（9.20） Redis（9.21） 2.每日计划： # 小徐的编程日记 Linux 就该这么学 Rust 相关文档 3.整理计划： # 整理笔记 数据采集 Grafana 完善 ","date":"3 September 2023","permalink":"/diary/todo/","section":"Diaries","summary":"1.","title":"计划"},{"content":"","date":"3 September 2023","permalink":"/tags/questions/","section":"Tags","summary":"","title":"Questions"},{"content":"搜集来的一些问题，每天问问自己\nL4、L7 ","date":"3 September 2023","permalink":"/diary/questions/","section":"Diaries","summary":"搜集来的一些问题，每天问问自己","title":"问题日志"},{"content":"","date":"16 August 2023","permalink":"/cloud/","section":"Clouds","summary":"","title":"Clouds"},{"content":"","date":"16 August 2023","permalink":"/tags/grafana/","section":"Tags","summary":"","title":"Grafana"},{"content":"在自己的电脑上配了个 Grafana 的环境，有一些坑，作为记录\n1.ubuntu 桌面安装 Grafana 前传（Docker） # 因为打算在自己电脑上起一个 grafana 的镜像，所以没有使用 portainer 的方式用 compose 去管理、拉取镜像和运行容器（占内存（虽然不大））\n1.1 Docker 安装 # 1.1.1 安装 Docker Engine # 设置存储库 # 更新apt包索引并安装包以允许apt通过 HTTPS 使用存储库： sudo apt-get update sudo apt-get install ca-certificates curl gnupg 添加Docker官方GPG密钥： sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg 使用以下命令设置存储库： echo \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null 更新apt包索引： sudo apt-get update 安装 Docker 引擎 # 安装 Docker 引擎、containerd 和 Docker Compose sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 通过运行镜像来验证Docker Engine安装是否成功 hello-world sudo docker run hello-world 如果本地没有该镜像，这个命令将会下载测试镜像，在容器中运行它，打印出 \u0026ldquo;Hello from Docker\u0026rdquo;，并且退出\n至此，已经成功安装并启动了 Docker Engine 官方文档：https://docs.docker.com/engine/install/ubuntu/\n1.1.2 安装 Docker Desktop（非必要） # 在 Ubuntu 上安装 Docker Desktop 的推荐方法：\n设置 Docker 的包存储库 下载最新的 DEB 包 使用 apt 安装软件包，如下所示： sudo apt-get update sudo apt-get install ./docker-desktop-\u0026lt;version\u0026gt;-\u0026lt;arch\u0026gt;.deb 官方文档：https://docs.docker.com/desktop/install/ubuntu/\n1.2 Docker 设置 # 1.2.1 添加用户组（以非 root 用户身份管理 Docker） # Docker 守护进程绑定到 Unix 套接字而不是 TCP 端口，默认情况下，Unix 套接字归 root 用户所有，其他用户只能使用sudo，Docker 守护程序始终以 root 用户身份运行\n如果不想在 docker 命令前加上 sudo，可以创建 docker 组并将用户添加到其中，当 Docker 守护进程启动时，它会创建一个可供 docker 组成员访问的 Unix 套接字\n创建 docker 组 sudo groupadd docker 将用户添加到 docker 组中 sudo usermod -aG docker $USER $USER是一个环境变量，代表当前用户名\n刷新docker组，使其改动直接生效 newgrp docker 1.2.2 将 Docker 配置为开机启动 # 大多数当前的 Linux 发行版（RHEL、CentOS、Fedora、Debian、Ubuntu 16.04 和更高版本）用于systemd管理系统启动时启动的服务。在 Debian 和 Ubuntu 上，Docker 服务默认配置为在启动时启动。要在启动时为 Docker 和 Containerd自动启动其他发行版，请使用以下命令：\nsudo systemctl enable docker.service sudo systemctl enable containerd.service 要禁用此行为，请改用 disable\nsudo systemctl disable docker.service sudo systemctl disable containerd.service 1.2.3 Docker 常用挂载的三种方式 # 绑定挂载：绑定挂载是将主机上的文件或目录挂载到容器中。这种挂载方式允许容器与主机之间共享文件和目录，并且对其中一个的更改会直接影响到另一个。可以通过在运行容器时使用 -v 或 \u0026ndash;mount 参数来指定绑定挂载，例如： docker run -v /host/path:/container/path image_name 卷挂载（Volume Mounts）：卷挂载将 Docker 数据卷挂载到容器中。数据卷是一个可供一个或多个容器使用的特殊目录，用于存储数据和共享数据。它独立于容器的生命周期，容器可以在挂载点读取和写入数据，就像使用普通目录一样。可以通过在运行容器时使用 -v 或 \u0026ndash;mount 参数指定卷挂载，例如： docker run -v volume_name:/container/path image_name 临时文件系统（tmpfs）挂载：临时文件系统挂载允许将临时文件系统挂载到容器的指定路径。与绑定挂载和卷挂载不同，临时文件系统挂载仅在容器的生命周期内存在，并且不会对主机文件系统产生影响。可以通过在运行容器时使用 \u0026ndash;tmpfs 参数来指定临时文件系统挂载，例如： docker run --tmpfs /container/path image_name 2.Grafana 安装（正题） # 2.1 试错1 # docker run -d -p 3000:3000 -i --name grafana -v /home/static/csv:/var/lib/grafana/static/csv grafana/grafana 可以，但是缺少 ini 的映射，以及 grafana local mode has been disabled by your administrator 问题，后文解决\n2.2 试错2 # docker run --user root -d -p 3000:3000 --name grafana -v /home/static/csv:/opt/static/csv -v /home/swap/grafana:/etc/grafana/grafana.ini grafana/grafana 补充 ini 的配置映射后，有权限问题，无法直接映射（during container init: error mounting to rootfs at \u0026ldquo;/etc/grafana/grafana.ini\u0026rdquo;: mount /etc/grafana/grafana.ini (via /proc/self/fd/9)）\n2.3 试错3 # 关于 grafana local mode has been disabled by your administrator 的问题，根据 ChatGPT 的提示，去设置 allow_embedding 或类似的设置来控制本地模式的启用或禁用\ndocker run -d -p 3000:3000 -i --name grafana -v /home/static/csv:/opt/static/csv -e \u0026#34;GF_ALLOW_EMBEDDING=true\u0026#34; grafana/grafana 遇到了 Error response from daemon: invalid mode 的错误，使用了无效的模式\n2.4 解决 # 开启特权模式，同时允许 csv 相关数据的映射\ndocker run -d -p 3000:3000 -i --name grafana -v /home/static/csv:/opt/static/csv -e \u0026#34;GF_PLUGIN_ALLOW_LOCAL_MODE=true\u0026#34; grafana/grafana 更新：由于希望用户（被分享者）可以匿名查看看板（无密码访问）\ndocker run -d -p 3000:3000 -i --name grafana -v /home/static/csv:/opt/static/csv -e \u0026#34;GF_PLUGIN_ALLOW_LOCAL_MODE=true\u0026#34; -e \u0026#34;GF_AUTH_ANONYMOUS_ENABLED=true\u0026#34; grafana/grafana 总结：因为偷懒，没有做 grafana.ini 文件的映射，所以采取的是 GF_ 变量覆盖的方式去自定义 Grafana 相关的设置\n其他资料：https://www.cnblogs.com/woshimrf/p/docker-grafana.html\n3.Grafana csv 数据源使用技巧 # 因为相关数据的敏感性及 Python 大数据操作的便利性，所以存在以 csv 为数据源进行 Grafana 看板展示的需求（所以前面才会折腾本地模式的数据映射，就是为了 csv 数据源做铺垫（不涉及时序））\n前面的数据映射已经完成，现在只说一下如何在 Grafana 中配置数据源及相关使用技巧\n3.1 安装 csv 数据源插件 # 资料：http://zh-tw.dgrt.cn/a/1664648.html?action=onClick\n4.Grafana 免密登录 # 如果使用 ini 修改配置如下：\n[auth.anonymous] # enable anonymous access enabled = true #默认false # specify role for unauthenticated users org_role = Viewer #默认Viewer 使用环境变量，修改如下：\nGF_AUTH_ANONYMOUS_ENABLED=true 资料：（使用环境变量进行配置）\nhttps://www.freesion.com/article/2928606237/ https://www.mayanpeng.cn/archives/146.html ","date":"16 August 2023","permalink":"/cloud/grafana/skills/","section":"Clouds","summary":"在自己的电脑上配了个 Grafana 的环境，有一些坑，作为记录","title":"Grafana 本地安装"},{"content":"","date":"12 August 2023","permalink":"/tags/docker/","section":"Tags","summary":"","title":"Docker"},{"content":"Dockerfile 相关内容\n1.docker 相关操作技巧 # 如果 docker 的命令需要添加 sudo 的执行权限，每次都要输入 sudo 比较麻烦，可以通过 id nick 的命令查看当前系统中的用户角色及相关的 group，然后 addgroup -a nick docker，把当前角色加入到 docker 的组中（nick 是角色名）（去掉 sudo）\nid nick sudo addgroup -a nick docker sudo service docker restart 2.如何创建镜像 # 2.1 不使用缓存编译 # docker 缓存镜像的规则：每一行 dockerfile 是一层，dockerfile 内容没变 cache 不会变（dockerfile 没改过，他就一直用缓存），可以通过 \u0026ndash;no-cache 刷新缓存，强制重新编译\n2.2 dockerfile 关键词 # 关键词：\nFROM：使用的基础镜像，其实就是文件系统（root fs）（可以有多个 FROM 作为后面的基础镜像去使用） MAINTAINER：作者 LABEL：tag 版本（todo 1.2） RUN：执行的指令 EXPOSE：容器暴露的端口（可以做映射，但最好不做，更灵活，根据实际情况映射） CMD：容器的启动命令 ENV：容器的环境变量 ADD：添加网络文件，指定一个路径，下载并添加到容器；tar.gz 自动加压（有些压缩包解压不了，需要注意） COPY：只是把宿主机的文件拷贝到容器镜像（不能解压），或者从上一个编译结果 copy 到下一个编译过程（COPY \u0026ndash;from） entrypoint：容器的入口程序 volume：过载磁盘 user：运行的身份 workdir：工作目录 arg：编译镜像时可以加入参数 onbuild：下载一些指令 stopsignal：容器的退出信号（通过docker history 查看一下） 前一阶段的结果 copy 到第二阶段的编译过程，前面的镜像会被删掉抛弃掉，不占容器的空间，因为已经编译完了，拿到了想要的结果，最终的基础镜像是这个 alpine，只有 11M 这个有 1.1G，所以上面的方法是一个减小镜像大小的手段\ndocker rm 是删除容器\ndocker rmi 是删除镜像\n注意：镜像就是一个文件系统，不包括内核之类的依赖\n2.3 干净的 kill 一个容器 # 通过 docker events 观察\ndocker stop：本质 kill exitCode=0 signal=3（可以理解为 docker kill 的一种特殊情况，可以感觉的 kill 掉一个进程，可以帮助我们把进程的守卫收拾干净）\ndocker kill：exitCode=137 signal=9（可能进程终止了，没有去收拾守卫进程）\n","date":"12 August 2023","permalink":"/cloud/docker/dockerfile/","section":"Clouds","summary":"Dockerfile 相关内容","title":"Dockerfile 相关内容"},{"content":"Grafana docker compose 安装记录及问题总结\n1.网上相关写法 # 1.1 docker compose # version: \u0026#39;3\u0026#39; services: grafana: image: \u0026#34;grafana/grafana\u0026#34; container_name: grafana restart: always ports: - \u0026#39;3000:3000\u0026#39; volumes: - \u0026#34;./etc/data:/var/lib/grafana\u0026#34; - \u0026#34;./etc/grafana.ini:/etc/grafana/grafana.ini\u0026#34; - \u0026#34;./etc/localtime:/etc/localtime\u0026#34; environment: - GF_USERS_ALLOW_SIGN_UP=false - GF_USERS_ALLOW_ORG_CREATE=false - GF_USERS_AUTO_ASSIGN_ORG_ROLE=Read Only Editor - GF_DATABASE_TYPE=mysql - GF_DATABASE_HOST=host:port - GF_DATABASE_NAME=grafana - GF_DATABASE_USER=root - GF_DATABASE_PASSWORD=****** 1.2 字段解释 # GF_USERS_ALLOW_SIGN_UP：设置为 false 时表示禁止⽤用户注册、创建用户账号，默认为 false；但管理员用户仍然可以从 Grafana 管理界面创建用户 GF_USERS_ALLOW_ORG_CREATE：设置为 false 禁⽌用户创建新组织，默认为 false GF_USERS_AUTO_ASSIGN_ORG_ROLE：新⽤户将分配给主要组织的角色，默认为 viewer，其他有效选项为 admin 和 editor GF_DATABASE_TYPE：数据库类型，⽆非就是 mysql、postgres 或者 sqlites GF_DATABASE_HOST：仅适⽤于 mysql 或 postgres，包括 ip 或主机名和端口，例如，对于 Grafana 在同一台主机上运行时 mySQL: host = 127.0.0.1 : 3306 GF_DATABASE_NAME：Grafana 数据库名称，下述中为是定义为 grafana_test GF_DATABASE_USER：数据库用户，不适用于 sqlites3 GF_DATABASE_PASSWORD：数据库⽤户密码(不适⽤于 sqlites)，如果密码中包含 # 或 ; 则必须用3个 （以上 docker compose 及字段解释均源于网络）\n2.踩坑记录 # 上面的写法看起来没什么问题，但是在实际的部署、运行过程中存在着很多的坑\n2.1 问题1： # can\u0026rsquo;t create directory \u0026lsquo;/var/lib/grafana/plugins\u0026rsquo;: Permission denied\nlevel=error msg=\u0026ldquo;alert migration failure: could not get migration log\u0026rdquo; error=\u0026ldquo;failed to check table existence: dial tcp: address tcp/\u0026lt;25615\u0026gt;: unknown port\u0026rdquo;\n2. 问题： # GF_PATHS_DATA=\u0026rsquo;/var/lib/grafana\u0026rsquo; is not writable\nversion: \u0026#39;3\u0026#39; services: grafana: image: grafana/grafana container_name: grafana restart: always ports: - 3000:3000 user: \u0026#39;0\u0026#39; volumes: - /home/docker/grafana/data:/var/lib/grafana - /home/docker/grafana/plugins:/var/lib/grafana/plugins environment: - GF_DATABASE_TYPE=mysql - GF_DATABASE_HOST= - GF_DATABASE_PORT= - GF_DATABASE_NAME=grafana - GF_DATABASE_USER=root - GF_DATABASE_PASSWORD=******* ","date":"10 August 2023","permalink":"/cloud/grafana/install/","section":"Clouds","summary":"Grafana docker compose 安装记录及问题总结","title":"Grafana 安装配置"},{"content":"","date":"10 August 2023","permalink":"/tags/install/","section":"Tags","summary":"","title":"Install"},{"content":"Redis docker compose 安装记录\nversion: \u0026#34;3.0\u0026#34; services: redis: image: redis ports: - 6379:6379 volumes: #Redis持久化数据映射 - /home/docker/redis/data:/data #准备自己的redis配置文件，包含redis连接密码 - /home/docker/redis/config:/etc/redis/redis.conf #redis存储路径 - /home/docker/redis/logs:/logs # 容器启动后在容器中执行的命令，启动redis,appendonly参数可用来持久化redis数据参数 # 覆盖容器启动后默认执行的命令 # command: redis-server /usr/local/etc/redis/redis.conf command: redis-server --requirepass ****** restart: always ","date":"9 August 2023","permalink":"/cloud/redis/install/","section":"Clouds","summary":"Redis docker compose 安装记录","title":"Redis 安装配置"},{"content":"","date":"30 July 2023","permalink":"/tags/git/","section":"Tags","summary":"","title":"Git"},{"content":"介绍 Git 相关的操作指令\n1.Git 常用指令 # 切换分支 git checkout test 创建并切换分支 git checkout -b test 拉取更新代码 git pull 查看 git 配置文件（全局） vi ~/.gitconfig git config --global --edit 测试 ssh 方式访问 gitlab ssh -T git@git.n.***.com 查看 ssh 文件 cd ~/.ssh cat id_rsa.pub git config 配置 git config --global user.name \u0026#34;newtsun\u0026#34; git config --global user.email \u0026#34;newtsun@*.com\u0026#34; git config --global --replace-all user.（如果冲突，可以 ） 2.Git fetch 和 Git pull 区别 # git fetch\n在拉取代码过程中，git fetch会首先检查本地仓库和远程仓库的差异，检查哪些不存在于本地仓库，然后将这些变动的提交拉取到本地。\n但是，这里请注意，它是把远程提交拉取到本地仓库，而不是本地 工作目录，它不会自行将这些新数据合并到当前工作目录中，我们需要继续执行git merge才会把这些变动合并到当前工作目录。\ngit pull\ngit pull和git fetch刚好相反，它直接获取远程的最新提交，直接拉取并合并到本地工作目录，而且在合并过程中不会经过我们的审查，如果不仔细检查，这样很容易遇到冲突。\n理解了git pull和git fetch的区别，那么该用哪种方式呢？\n相比之下，git fetch是一个更安全的选择，因为它从你的远程仓库拉入所有的提交，但不会对你的本地文件做任何修改。\n这给了你足够时间去发现远程仓库自从你上次拉取后到现在为止发生的变化。\n你可以在合并前检查哪些文件有变化，哪些文件可能导致冲突。\n而git pull相当于运行git fetch，然后立即将你的改动合并到本地仓库。这样的确少了一个步骤，但是也会带来一些风险。\n","date":"30 July 2023","permalink":"/cloud/git/","section":"Clouds","summary":"介绍 Git 相关的操作指令","title":"Git 常用操作"},{"content":"","date":"23 July 2023","permalink":"/tags/update/","section":"Tags","summary":"","title":"Update"},{"content":"Blog 更新日志\n2023.07.30 # Update Linux、Diary Add Cloud 2023.07.23 # Update Linux、Diary、Golang 2023.07.15 # First Commit ","date":"23 July 2023","permalink":"/diary/update/","section":"Diaries","summary":"Blog 更新日志","title":"更新日志"},{"content":"","date":"22 July 2023","permalink":"/tags/commands/","section":"Tags","summary":"","title":"Commands"},{"content":"Linux 常用的命令及相关的基础知识\n1.Linux 常用指令 # 安装 sudo dpkg -i package_name.deb 复制 sudo cp -r ~/下载/jbr jbr 删除 sudo rm -r Goland-2023.1.2/ 查看进程并过滤所需的端口 netstat -anp | grep 5678 查看 lsof -i：5678 删除 kill -9 174189 goland 安装 sudo tar -C /usr/local -xzf goland-2020.3.4.tar.gz hostname hostname -I df 查看当前系统中挂载的文件系统类型、各文件系统 inode 使用情况及文件系统挂载点 df -i --print-type ctrl + h // 查看隐藏文件 // 使用该 file 实用程序指示行结尾的类型 file testfile.txt 找出文本行尾符： https://stackoverflow.com/questions/3569997/how-to-find-out-line-endings-in-a-text-file\n2.vim 学习及指令 # vim一共分为三种模式，分别为：命令模式，输入模式，退出模式。\n启动vim，进入命令模式，在这样的状态下输入任何东西都会被vim识别为命令，比如我们输入i，并不是输入的是字符而是i这个命令。那么“i” 就是常用的命令，他表示切换到输入模式，只有进入到输入模式才能输入字符。\n命令模式：:表示切换到命令模式，在最后一行输入命令 输入模式：进入到vim中，按下i命令，进入输入模式，在输入模式中可以使用以下指令 退出模式：在输入完之后想保存退出，那么就要用到以下 q：表示退出，没有做过任何编辑 wq：编辑完之后，保存并退出 q!：强制退出，放弃修改 wq!：强制退出并保存（对自己的文件或者root用户） 3.Linux 程序安装 # 3.1 deb 安装 # sudo dpkg -i package_name.deb 3.2 AppImage 安装 # // 在 /opt/ 创建程序文件夹 sudo mkdir /opt/obsidian // 将下载的 AppImage 文件移动至该文件下 sudo mv ~/Downloads/Obsidian-0.12.19.AppImage /opt/obsidian/Obsidian-0.12.19.AppImage // 赋予执行权限 chmod 777 /opt/obsidian/Obsidian-0.12.19.AppImage // 在 /bin/ 文件下做一个链接 sudo ln -s /opt/obsidian/Obsidian-0.12.19.AppImage /bin/ // 加入启动器 sudo vi /usr/share/applications/obsidian.desktop // 编辑内容 [Desktop Entry] Encoding=UTF-8 Name=Obsidian Exec=/opt/obsidian/Obsidian-0.12.19.AppImage Icon=/opt/obsidian/Obsidian.png Terminal=False Type=Application StartupNotify=False Categories=Application;Development // 好像也有简版 [Desktop Entry] Name=obsidian Exec=/opt/Obsidian-1.3.5-arm64.AppImage Icon=/home/orangepi/Pictures/obsidian.png Type=Application StartupNotify=true ","date":"22 July 2023","permalink":"/linux/learn/commands/","section":"Linuxes","summary":"Linux 常用的命令及相关的基础知识","title":"Linux 常用命令"},{"content":"","date":"22 July 2023","permalink":"/linux/","section":"Linuxes","summary":"","title":"Linuxes"},{"content":"把之前写的一些面经逐渐迁移过来了\u0026hellip;\n1.原子操作 # 原子操作的意思是说，这个操作在执行的过程中，其它协程不会看到执行一半的操作结果。\n在单处理器单核系统中，即使一个操作翻译成汇编不止一个指令，也有可能保持一致性。比如经常用来演示的并发场景下的 count++ 操作 （count++ 对应的汇编指令就有三条），如果像下面这样写：\nfunc main() { runtime.GOMAXPROCS(1) var w sync.WaitGroup count := int32(0) w.Add(100) for i := 0; i \u0026lt; 100; i++ { go func() { for j := 0; j \u0026lt; 20; j++ { count++ } w.Done() }() } w.Wait() fmt.Println(count) } 而在多核系统中，情况就变得复杂了许多。A核修改 count 的时候，由于 CPU 缓存的存在，B核读到的 count 值可能不是最新的值。如果我们将上面的例子中的第二行改成：\nruntime.GOMAXPROCS(2) 之后，程序每执行一次，结果都有可能不一样。\n解决思路除了使用前面介绍过的 Mutex，也可以使用今天要介绍的 atomic，具体使用方法是将 count++ 替换成：\natomic.AddInt32(\u0026amp;count, 1) 这样就能保证即使在多核系统下 count++ 也是一个原子操作。\n针对一些基本的原子操作，不同的 CPU 架构中有不同的机制来保证原子性，atomic 包将底层不同架构的实现进行了封装，对外提供通用的 API。\natomic 的基础方法：\n原子操作主要是两类：修改和加载存储。修改很好理解，就是在原来值的基础上改动；加载存储就是读写。\natomic 提供了 AddXXX、CompareAndSwapXXX、SwapXXX、LoadXXX、StoreXXX 等方法。\n需要注意的是，atomic 的操作对象是地址，所以传参的时候，需要传变量的地址，不能传变量的值。\n来源： https://zhuanlan.zhihu.com/p/359971105\n2.Map 的底层实现 # 底层是 hmap 结构体，通过调用runtime.makemap函数，主要工作就是初始化 hmap 结构体的各个字段，hmap 里维护着若干个 bucket 数组 (即桶数组)，bucket 数组中每个元素都是 bmap 结构，也即每个bucket（桶）都是bmap结构，每个桶中保存了8个kv对，如果8个满了，会使用 overflow 连接下一个桶(溢出桶)。\n计算 key 的hash值 通过最后的“B”位来确定在哪号桶，如果B为4，所以取 key 对应哈希值的后4位 根据 key 对应的 hash 值前8位快速确定是在这个桶的哪个位置（tophash） 对比key完整的hash是否匹配，如果匹配则获取对应value 如果都没有找到，就去连接的下一个溢出桶中找 扩容方式：\n相同容量扩容（元素会发生重排，但不会换桶） 2倍容量扩容（元素会重排，可能会发生桶迁移） type hmap struct { count int // 元素的个数 B uint8 // buckets 数组的长度就是 2^B 个 overflow uint16 // 溢出桶的数量 buckets unsafe.Pointer // 2^B个桶对应的数组指针 oldbuckets unsafe.Pointer // 发生扩容时，记录扩容前的buckets数组指针 extra *mapextra //用于保存溢出桶的地址 } type mapextra struct { overflow *[]*bmap oldoverflow *[]*bmap nextOverflow *bmap } type bmap struct { tophash [bucketCnt]uint8 } //在编译期间会产生新的结构体 type bmap struct { tophash [8]uint8 //存储哈希值的高8位 data byte[1] //key value数据:key/key/key/.../value/value/value... overflow *bmap //溢出bucket的地址 } 3.sync.Map 的底层实现 # sync.Map 的设计利用了 atmoic 和 mutex 的配合：\n使用了两个原生的 map 作为存储介质，分别是 read map 和 dirty map（只读字典和脏字典）。 只读字典使用 atomic.Value 来承载，保证原子性和高性能；脏字典则需要用互斥锁来保护，保证了互斥。 只读字典和脏字典中的键值对集合并不是实时同步的，它们在某些时间段内可能会有不同。 无论是 read 还是 dirty，本质上都是 *map[interface{}]entry 类型，这里的 entry 其实就是 Map 的 value 的容器。 entry 的本质，是一层封装，可以表示具体值的指针，也可以表示 key 已删除的状态（即逻辑假删除） 通过这种设计，规避了原生 map 无法并发安全 delete 的问题，同时在变更某个键所对应的值的时候，就也可以使用原子操作了\n4.goroutine 的原理 # 基于CSP并发模型开发了GMP调度器：\n1.G：是Goroutine的缩写，是Goroutine的控制结构，对 Goroutine 的抽象。其中包括执行的函数指令及参数；G 保存的任务对象；线程上下文切换，现场保护和现场恢复需要的寄存器(SP、IP)等信息。在 Go 语言中使用 runtime.g 结构表示。\n2.M：是内核线程，由操作系统调度以及管理，调度器最多可以创建 10000 个线程，在 Go 语言中使用 runtime.m 结构表示。（用户线程与内核线程的映射关系）\n3.P：是调度各个goroutine，使他们之间协调运行的逻辑处理器，但不代表真正的CPU的数量，真正决定并发程度的是P，初始化的时候一般会去读取GOMAXPROCS对应的值，如果没有显示设置，则会读取默认值，在Go1.5之后GOMAXPROCS被默认设置可用的核数，而之前则默认为1，在 Go 语言中使用 runtime.p 结构表示。\n4.指定cpu线程个数\n通过runtime.GOMAXPROCS()，可以指定P的个数,如果没有指定则默认跑满整个cpu\n5.GMP 调度模型 # goroutine 的调度是 Go 语言运行时（runtime）层面的实现，由 Go 语言本身实现的一套调度系统：go scheduler。是按照一定的规则将所有的 goroutine 调度到操作系统线程上执行。目前 Go 语言的调度器采用的是 GPM 调度模型。\nG：表示 goroutine，每执行一次go f()就创建一个 G，包含要执行的函数和上下文信息 全局队列（Global Queue）：存放等待运行的 G P：是调度各个goroutine，使他们之间协调运行的逻辑处理器，表示 goroutine 执行所需的资源，最多有 GOMAXPROCS 个 P 的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建 G 时，G 优先加入到 P 的本地队列，如果本地队列满了会批量移动部分 G 到全局队列 M：是内核线程，由操作系统调度以及管理，线程想运行任务就得获取 P，从 P 的本地队列获取 G，当 P 的本地队列为空时，M 也会尝试从全局队列或其他 P 的本地队列获取 G。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去 Goroutine 调度器和操作系统调度器是通过 M 结合起来的，每个 M 都代表了1个内核线程，操作系统调度器负责把内核线程分配到 CPU 的核上执行 调度器的设计策略：\n复用线程：避免频繁的创建、销毁线程，而是对线程的复用\nwork stealing 机制：当本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程 hand off 机制：当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行 利用并行：GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个CPU上同时运行，GOMAXPROCS也限制了并发的程度，比如GOMAXPROCS = 核数/2，则最多利用了一半的CPU核进行并行\n抢占：在 coroutine 中要等待一个协程主动让出CPU才执行下一个协程，在Go中，一个goroutine最多占用CPU 10ms，防止其他goroutine被饿死，这就是goroutine不同于coroutine的一个地方\n全局G队列：在新的调度器中依然有全局G队列，但功能已经被弱化了，当M执行work stealing从其他P偷不到G时，它可以从全局G队列获取G\n6.channel 的底层实现 # channel 的操作封装在 runtime 包下的 chan.go 文件\ntype hchan struct { qcount uint // channel中环形队列数据总数，len()返回该值 dataqsiz uint // 环形队列的长度，make时指定，cap()返回该值 buf unsafe.Pointer // 指向环形队列的指针，缓存区基于环形队列实现 elemsize uint16 // 元素的大小 closed uint32 // channel关闭标志 elemtype *_type // 元素类型 sendx uint // 向channel发送数据时，写入的位置索引 recvx uint // 从channel读数据时，读取的位置索引 recvq waitq // buf空时，读取的goroutine等待队列 sendq waitq // buf满时，写入的goroutine等待队列 // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G\u0026#39;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex // 并发控制锁，同一时刻，只允许一个 } // 等待goroutine的双向链表结构 type waitq struct { first *sudog last *sudog } 7.unsafe.Pointer 的使用 # 7.1 使用 unsafe.Pointer 做类型转换 # 可以简洁适宜的转换两个在内存中结构一样的类型是使用 unsafe.Pointer 的一个主要原因。\n文档描述：\n如果T2与T1一样大，并且两者有相同的内存结构；那么就允许把一个类型的数据，重新定义成另一个类型的数据\n经典的例子，是文档中的一次使用，用来实现 math.Float64bits：\nfunc Float64bits(f float64) uint64 { return *(*uint64)(unsafe.Pointer(\u0026amp;f)) } 这似乎是一种非常简洁的完成这样转换的方法，但是这个过程中具体发生了什么？让我们一步步拆分一下：\n\u0026amp;f 拿到一个指向 f 存放 float64 值的指针。 unsafe.Pointer(\u0026amp;f) 将 *float64 类型转化成了 unsafe.Pointer 类型。 (uint64)(unsafe.Pointer(\u0026amp;f)) 将 unsafe.Pointer 类型转化成了 uint64。 _(_uint64)(unsafe.Pointer(\u0026amp;f)) 引用这个 *uint64 类型指针，转化为一个 uint64 类型的值。 第一个例子是下面过程的一个简洁表达：\nfunc Float64bits(floatVal float64) uint64 { // 获取一个指向存储这个float64类型值的指针。 floatPtr := \u0026amp;floatVal // 转化*float64类型到unsafe.Pointer类型。 unsafePtr := unsafe.Pointer(floatPtr) // 转化unsafe.Pointer类型到*uint64类型. uintPtr := (*uint64)(unsafePtr) // 解引用成一个uint64值 uintVal := *uintPtr return uintVal } 7.2 使用 unsafe.Pointer 处理系统调用 # 当处理系统调用时，有些时候需要传入一个指向某块内存的指针给内核，以允许它执行某些任务。这是 unsafe.Pointer 在 Go 中另一个重要的使用场景。当需要处理系统调用时，就必须使用 unsafe.Pointer，因为为了使用 syscall.Syscall 家族函数，它可以被转化成 uintptr 类型。\n对于许多不同的操作系统，都拥有大量的系统调用。但是在这个例子中，我们将重点关注 ioctl 。ioctl，在UNIX类系统中，经常被用来操作那些无法直接映射到典型的文件系统操作，例如读和写的文件描述符。事实上，由于 ioctl 系统调用十分灵活，它并不在Go的 syscall 或者 x/sys/unix 包中。\n让我看看另一个真实的例子。\n现实例子：ioctl / vsock\n在过去的几年里，Linux 增加了一个新的 socket 家族，AF_VSOCK，它可以使管理中心和它的虚拟机之间双向，多对一的通信。 这些套接字使用一个上下文 ID 进行通信。通过发送一个带有特殊请求号的 ioctl 到 /dev/vsock 驱动，可以取到这个上下文 ID。\n下面是 ioctl 函数的定义：\nfunc Ioctl(fd uintptr, request int, argp unsafe.Pointer) error { _, _, errno := unix.Syscall( unix.SYS_IOCTL, fd, uintptr(request), // 在这个调用表达式中，从 unsafe.Pointer 到 uintptr 的转换是必须做的。详情可以查看 unsafe 包的文档 uintptr(argp), ) if errno != 0 { return os.NewSyscallError(\u0026#34;ioctl\u0026#34;, fmt.Errorf(\u0026#34;%d\u0026#34;, int(errno))) } return nil } 像代码注释所写一样，在这种场景下使用 unsafe.Pointer 有一个很重要的说明：\n在 syscall 包中的系统调用函数通过它们的 uintptr 类型参数直接操作系统，然后根据调用的详细情况，将它们中的一些转化为指针。换句话说，系统调用的执行，是其中某些参数从 uintptr 类型到指针类型的隐式转换。 如果一个指针参数必须转换成 uintptr 才能使用，那么这种转换必须出现在表达式内部。\n但是为什么会这样？这是编译器识别的特殊模式，本质上是指示垃圾收集器在函数调用完成之前，不能将被指针引用的内存再次安排。\n你可以通过阅读文档来获得更多的技术细节，但是你在Go中处理系统调用时必须记住这个规则。事实上，在写这篇文章时，我意识到我的代码违反了这一规则，现在已经被修复了。\n意识到这一点，我们可以看到这个函数是如何使用的。\n在 VM 套接字的例子里，我们想传递一个 *uint32 到内核，以便它可以把我们当时的上下文ID赋值到这块内存地址中。\nf, err := fs.Open(\u0026#34;/dev/vsock\u0026#34;) if err != nil { return 0, err } defer f.Close() // 存储上下文ID var cid uint32 // 从这台机器的 /dev/vsock 中获取上下文ID err = Ioctl(f.Fd(), unix.IOCTL_VM_SOCKETS_GET_LOCAL_CID, unsafe.Pointer(\u0026amp;cid)) if err != nil { return 0, err } // 返回当前的上下文ID给调用者 return cid, nil 这只是在系统调用时使用 unsafe.Pointer 的一个例子。你可以使用这么模式发送、接收任何数据，或者是用一些特殊方式配置一个内核接口。有很多可能的情况\n","date":"22 July 2023","permalink":"/golang/interview/ed/","section":"Golang","summary":"把之前写的一些面经逐渐迁移过来了\u0026hellip;","title":"Go 面经"},{"content":"关于 Golang 的一些学习分享\u0026hellip;\n","date":"22 July 2023","permalink":"/golang/","section":"Golang","summary":"关于 Golang 的一些学习分享\u0026hellip;","title":"Golang"},{"content":"","date":"22 July 2023","permalink":"/tags/interview/","section":"Tags","summary":"","title":"Interview"},{"content":"","date":"22 July 2023","permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux"},{"content":"文件系统\n1.文件系统 # 任何技术的出现是为了解决问题，文件系统也是为了解决某些问题。那文件系统是为了解决什么问题呢？\n我们有了一个相对形象的概念，文件系统管理着很多文件。而这些文件其实就是数据，这些数据又是存储在磁盘上的。因此，实质上文件系统是管理磁盘的软件系统，它简化了用户对磁盘空间的使用方法，并降低了磁盘空间的使用难度，通过更加形象的方式将磁盘中的数据展示给用户。 赵二狗窃窃私语：“好啰嗦” 大家对磁盘都比较清楚，其实就是存储数据的地方，我们可以将磁盘与仓库类比。类似一个空仓库，一个没有格式化的磁盘就好像一个空仓库，空间非常大，我们可以随便使用。\n磁盘的内部虽然非常复杂，但磁盘生产厂商做了很多工作，将磁盘的复杂性掩盖起来了。对于普通用户来说，磁盘就是一个线性空间，就好像C语言中的数组一样，通过偏移就可以访问其空间（读写数据）。\n但是，我们虽然可以直接访问磁盘的空间，如果缺乏规划，那么使用的最终结果可能是这样样子的。数据被毫无规律的放到磁盘上，最后查找的时候会非常费劲，甚至可能找不到需要的数据。\n因此，文件系统出现了。文件系统实现对磁盘空间的统一管理，一方面文件系统对磁盘空间进行统一规划，另外一方面文件系统提供给普通用户人性化的接口。就好比仓库中的货架，将空间进行规划和编排，这样根据编号可以方便的找到具体的货物。而文件系统也是类似，将磁盘空间进行规划和编号处理，这样通过文件名就可以找到具体的数据，而不用关心数据到底是怎么存储的。\n以Ext4文件系统为例，它将磁盘空间进行划分，并通过元数据实现对磁盘空间的管理。这样，用户对文件的操作就转化为文件系统对磁盘空间的操作。 也就是说，文件系统解决了普通用户使用磁盘存储数据的问题。\n2.分布式文件系统 # 上面说的是普通本地文件系统的概念，比如Ext4、XFS、FAT32和Btrfs等文件系统。这些文件系统只能在本地进行磁盘格式化并使用。那么什么是分布式文件系统呢？下面是维基百科给出的定义。\n相对于本机端的文件系统而言，分布式文件系统（英语：Distributed file system, DFS），或是网络文件系统（英语：Network File System），是一种允许文件透过网络在多台主机上分享的文件系统，可让多机器上的多用户分享文件和存储空间。\n通过定义我肯可以看出，分布式文件系统解决的是资源共享的问题。我们先看一个实例，以NFS文件系统为例，它分为服务端和客户端，客户端通过某种协议连接到服务端，此时会在客户端的目录树中映射一个子树，这样在客户端就能访问服务端的文件系统。然而，对于客户端来说，这个目录树关系是透明的，也就是用户不知道这些内容是在远程计算机，也不用关心。\n分布式文件系统解决的最大的问题是资源共享的问题，因此分布式文件系统最大的特点是多个客户端可以访问相同的服务端。\n图 NFS可以供多个客户端访问，但其毕竟是单机，处理能力是有限的。因此在大规模数据领域，不如电商网站、大数据处理等，采用单机模式无法满足要求。问题有出来了，为了解决这个问题，谷歌开发了GFS分布式文件系统，该文件系统的服务端通过一个集群来实现，客户端可以并发的访问该集群的多达数万个节点，因此承载能力得到极大的提升。 如图10是HDFS的架构图，HDFS是GFS的开源实现，起基本架构是一样的。整个集群的节点分为2中角色，一个是Master节点，负责管理元数据；另外一个是数据节点，负责存储文件的数据。在这种架构中，客户端通过Master节点可以得到文件数据的具体位置，然后可以直接与数据节点交互。由于数据节点可以很多（数万个），因此承载能力得到极大的提升。\n除了上述HDFS和GFS等分布式文件系统外，还有GlusterFS、CephFS等很多分布式文件系统，但每种分布式文件系统的细节又有所差异，这个也是与它们所要解决的具体问题相关的。\n3.集群文件系统 # 虽然分布式文件系统可以处理高并发访问的问题，但对于同一个文件同时写会存在数据不一致的问题。这个需要客户端的应用做特殊处理。如图11所示，客户端1从服务端读取的某个文件的数据，而此时在客户端进行了追加写操作，由于网络延迟或者什么原因，数据并没有达到服务端。此时，客户端2读取了服务端的数据，显然此时数据是旧数据。如果此时客户端2进行写操作，无法保证服务端最终的数据是客户端1的还是客户端2的，因此存在不可预料的结果。\n为了解决同一个文件被不同客户端的应用并发写的问题，这个时候开发了集群文件系统。其中比较著名的是Oracle的OCFS2文件系统。OCFS2通过分布式锁解决了写并发的问题，如果有进程对某个文件的区域进行写操作时会加锁，这样其它客户端如果对相同区域写数据时就必须等待。这样，OCFS2文件系统就保证了数据的一致性。 到此为止，我们介绍文件系统的原理及市面上常见的各种类型的文件系统。通过分析我们看到，不同的文件系统解决的问题是不同的，因此应用场景也是有很大差异的。因此，大家在工作中如果选型时，也需要考虑这些差异。\n","date":"22 July 2023","permalink":"/linux/learn/file-system/","section":"Linuxes","summary":"文件系统","title":"文件系统"},{"content":"全文目录\n1.IO 多路复用 # 1.1 IO 多路复用解释 # 首先拆解多路复用一词：\n多路：存在多个待服务的对象 复用：只由一个执行单元提供服务 串联上述要点，多路复用指的是，由一个执行单元，同时对多个对象提供服务，形成一对多的服务关系\n打个比方：多名顾客在餐厅内用餐，考虑到经营成本，很难做到为每名顾客单独提供一名招待员作一对一服务，因此餐厅经理安排每名服务生固定负责几个餐桌，服务生在几个桌次间来回辗转提供服务，这个过程本质上就是一种多路复用\n在 linux 操作系统中，对 IO 多路复用的概念有着更加明确的定义：\n多路：存在多个需要处理 io event 的 fd（linux 中，一切皆文件，所有事物均可抽象为一个文件句柄 file descriptor，简称 fd） 复用：复用一个 loop thread 同时为多个 fd 提供处理服务（线程 thread 是内核视角下的最小调度单位；多路复用通常为循环模型 loop model，因此称为 loop thread） IO 多路复用中，loop thread 是提供服务的乙方；待处理 io event 的 fd 们是甲方。本着顾客是上帝的原则，乙方有义务为甲方提供更优质的服务，这里的服务质量就体现在一句话：”随叫随到，别让老板等久了”\n在餐厅顾客没有需求的时候，服务生趁着闲工夫摸个鱼打个盹也尚无不可。但是一旦顾客招呼时，服务生需要第一时间赶到对需求作出响应\n此外，由于服务生和顾客之间的服务关系是一对多，所以还要考虑到有多名顾客同时招呼时，服务生如何作兼容处理，让每名顾客都不至于产生被冷落的感觉。这是一门学问，也同样是计算机领域 IO 多路复用场景下需要解决的问题\n1.2 多路复用简单实现 # 1.2.1 阻塞 IO # 通过一段伪代码，来尝试让 IO 多路复用这个概念看起来更加具体一些：\n// 多个待服务的 fd fds = [fd1,fd2,fd3,...] // 遍历 fd 列表，末尾和首部相连，形成循环 i = 0 for { // 获取本轮待处理的 fd fd = fds[i] // 从 fd 中读数据 data = read(fd) // 处理数据 handle(data) // 推进遍历 i++ if i == len(fds){ i = 0 } } 上述搭了个架子，核心分为几步：\n定义了待处理的 fds 列表（多路） 循环遍历 fds 列表，每轮负责读一个 fd（复用） 这是个乞丐版的 IO 多路复用模型看起来似乎有那么点意思了. 然而其本质上是一种阻塞 IO 模型（Blocking IO，简称 BIO）. 事实上，上述实现存在一个致命的问题，那就是句柄 fd 默认的 io 操作是阻塞型的，因此倘若在读 fd1 的时候，io event 没到达，那么 loop thread 就会陷入阻塞，后续 fd2、fd3 哪怕有 io event 到达，也无法得到执行\n上述问题翻译成更形象的场景，大概就是：\nA桌顾客对服务生说，你先搁这候着，我看会儿菜单，一会点菜\n服务生于是站定A桌，打定主意在A桌点完菜之后再离开\n在此期间，服务生辖区内的B桌、C桌招呼有事，服务生也充耳不闻，只等A桌事情完结才肯挪动步子\n这样的服务显然不够到位，倘若人人如此，餐厅必然面临倒闭\n1.2.2 非阻塞 IO # 基于 BIO 存在的问题，我们进行一轮改进，核心是将 read 操作由同步阻塞操作改为带有尝试性的非阻塞操作。在读一个 fd 的时候，倘若 io event 已就绪就正常读取，否则就即时返回并抛出一个特定类型的错误，让 loop thread 能够正常执行下去，为其他 fd 提供服务\n// 多个待服务的 fd fds = [fd1,fd2,fd3,...] // 遍历 fd 列表，末尾和首部相连，形成循环 i = 0 for { // 获取本轮待处理的 fd fd = fds[i] // 尝试从 fd 中读数据，失败时不阻塞，而是抛出错误 data,err = tryRead(fd) // 读取数据成功，处理数据 if err == nil{ handle(data) } // 小睡一秒后再推进流程 sleep(1 second) // 推进遍历 i++ if i == len(fds){ i = 0 } } 上述伪代码核心步骤如下：\n定义了待处理的 fds 列表 遍历 fds 列表，每轮尝试从一个 fd 中读数据 倘若 io event 已就绪，则正常处理结果 倘若 io event 未就绪，只抛出错误，同样不阻塞流程 小睡一会儿，然后继续推进流程 这里确实解决阻塞 IO 中的问题，其本质上是一种非阻塞 IO 模型（Nonblocking IO，简称 NIO），但这里仍然存在问题，就是每轮处理之间的休眠时间。倘若在休眠期间，fd 中有 io event 到达，就无法被正常处理，这同样是一种不好的体验\n这一问题翻译成餐厅的场景，指的就是服务生每次主动问询或者为一名客人提供服务后，就要大喘气休息几分钟，期间对客人不管不顾，这样的服务态度客人同样不会买账\n那大家可能会问了，倘若把此处的休眠操作去除了如何？\n答案是同样有问题. 倘若不限制轮询的执行频率，那么不轮 fd 中是否有 io event，程序都会一直高强度运行，这会导致 CPU 空转，造成很大程度的资源浪费\n用餐厅的场景来聊，指的是餐厅招了个视听都不好的服务生，他感应不到客人的召唤，需要时时刻刻奔走在各个餐桌之间主动去询问客人们是否需要服务。这种情况下，哪怕客人们性子好不嫌烦，服务生自己也被这种高强度的反复横跳动作给累坏了\n那大家可能又问了. 餐厅就不能招个正常的服务生吗，让他在听到客人的招呼时就去提供服务，否则就在一边老实歇着\n没错，这就是正解，设计程序的码农们也是这么想的. 然而实际情况很悲催，在用户态视角下的程序正是哪一个耳目昏聩的服务生，对于 io event 的到达并没有能力做到准确地把握\n于是，这就需要引入操作系统内核的帮助，通过几个内核对外暴露的接口，来进行 IO 多路复用的优雅实现，做到真正意义上的“随叫随到”\n1.3 IO 多路复用的优雅实现 # linux 内核提供了三种经典的多路复用技术：\n从上图中可以看到，各个技术之间通过单向箭头连接，因此是一个持续演化改进的过程，select 最通用，但是相对粗糙；而 epoll 则最精致，在性能上也有着最优越的表现\npoll 在 select 的基础之上做了改进，但治标不治本，优化得不够彻底. 我们核心还是来对比看看 select 和 epoll 之间的共性和差异：\n（1）select\n一次可以处理多个 fd，体现多路，但 fd 数量有限，最多 1024 个 loop thread 通过 select 将一组 fd 提交到内核做监听 当 fd 中无 io event 就绪时，loop thread 会陷入阻塞 每当这组 fd 中有 io event 到达时，内核会唤醒 loop thread loop thread 无法精准感知到哪些 fd 就绪，需要遍历一轮 fd 列表，时间复杂度 O(N) 托付给内核的 fd 列表只具有一轮交互的时效，新的轮次中，loop thread 需要重新将监听的 fd 列表再传递给内核一次 （2）epoll\n每次处理的 fd 数量无上限 loop thread 通过 epoll_create 操作创建一个 epoll 池子 loop thread 通过 epoll_ctl 每次将一个待监听的 fd 添加到 epoll 池中 每当 fd 列表中有 fd 就绪事件到达时，会唤醒 loop thread，同时内核会将处于就绪态的 fd 直接告知 loop thread，无需额外遍历 综上所述，select 和 epoll 等多路复用操作利用了内核的能力，能在待监听 fd 中有 io event 到达时，将 loop thread 唤醒，避免无意义的主动轮询操作\n其中，epoll 相比于 select 的核心性能优势在于：\nloop thread 被唤醒时，能明确知道哪些 fd 需要处理，减少了一次额外遍历的操作，时间复杂度由 O(N) 优化到 O(1) epoll 通过将创建池子和添加 fd 两个操作解耦，实现了池中 fd 数据的复用，减少了用户态与内核态间的数据拷贝成本 2.EventPoll 原理 # 2.1 核心指令 # epoll 又称 EventPoll，使用很简单，包含三个指令：\nepoll_create epoll_ctl epoll_wait 未完待续\u0026hellip;\n","date":"19 July 2023","permalink":"/golang/learn/epoll/","section":"Golang","summary":"全文目录","title":"Go 网络 IO 模型之 EPOLL"},{"content":"","date":"19 July 2023","permalink":"/tags/learn/","section":"Tags","summary":"","title":"Learn"},{"content":"最近计划学习 Linux 内核相关内容，Professional Linux Kernel Architecture\n第一章：简介及概述 # 1.内核的任务 # 内核是硬件与软件之间的一个中间层，其作用是将应用程序的请求传递给硬件，并充当底层驱动程序，对系统中的各种设备和组件进行寻址。\n从应用程序的视角来看，内核可以被认为是一台增强的计算机，将计算机抽象到一个高层次上。例如，在内核寻址硬盘时，它必须确定使用哪个路径来从磁盘向内存复制数据，数据的位置，经由哪个路径向磁盘发送哪一条命令，等等。另一方面，应用程序只需发出传输数据的命令。实际的工作如何完成与应用程序是不相干的，因为内核抽象了相关的细节。应用程序与硬件本身没有联系，只与内核有联系，内核是应用程序所知道的层次结构中的最底层，因此内核是一台增强的计算机。 当若干程序在同一系统中并发运行时，也可以将内核视为资源管理程序。在这种情况下，内核负责将可用共享资源（包括CPU时间、磁盘空间、网络连接等）分配到各个系统进程，同时还需要保证系统的完整性。 另一种研究内核的视角是将内核视为库，其提供了一组面向系统的命令。通常，系统调用用于向计算机发送请求。借助于C标准库，系统调用对于应用程序就像是普通函数一样，其调用方式与其他函数相同。 2.实现策略 # 微内核：这种范型中，只有最基本的功能直接由中央内核（即微内核）实现。所有其他的功能都委托给一些独立进程，这些进程通过明确定义的通信接口与中心内核通信。例如，独立进程可能负责实现各种文件系统、内存管理等。（当然，与系统本身的通信需要用到最基本的内存管理功能，这是由微内核实现的。但系统调用层次上的处理则由外部的服务器进程实现。）理论上，这是一种很完美的方法，因为系统的各个部分彼此都很清楚地划分开来，同时也迫使程序员使用“清洁的”程序设计技术。这种方法的其他好处包括：动态可扩展性和在运行时切换重要组件。但由于在各个组件之间支持复杂通信需要额外的CPU时间，所以尽管微内核在各种研究领域早已经成为活跃主题，但在实用性方面进展甚微。 宏内核：：与微内核相反，宏内核是构建系统内核的传统方法。在这种方法中，内核的全部代码，包括所有子系统（如内存管理、文件系统、设备驱动程序）都打包到一个文件中。内核中的每个函数都可以访问内核中所有其他部分。如果编程时不小心，很可能会导致源代码中出现复杂的嵌套。 因为在目前，宏内核的性能仍然强于微内核，Linux仍然是依据这种范型实现的（以前亦如此）。\n3.内核的组成部分 # Linux 是整体式的宏内核：\n图1 内核的组成部分 3.1 进程、进程切换、调度 # 各个进程的地址空间是完全独立的，因此进程并不会意识到彼此的存在，从进程的角度来看，它会任务自己是系统中唯一的进程。如果进程想要彼此通信（例如交换数据），那么必须使用特定的内核机制。\n由于 Linux 是多任务系统，它支持（看上去）并发执行的若干进程。系统中真正在运行的进程数目最多不超过CPU数目，因此内核会按照短的时间间隔在不同的进程之间切换（用户是注意不到 的），这样就造成了同时处理多进程的假象。\n(1) 内核借助于CPU的帮助，负责进程切换的技术细节。必须给各个进程造成一种错觉，即CPU总是可用的。通过在撤销进程的CPU资源之前保存进程所有与状态相关的要素，并将进程置于空闲状态，即可达到这一目的。在重新激活进程时，则将保存的状态原样恢复。进程之间的切换称之为进程切换。\n(2) 内核还必须确定如何在现存进程之间共享CPU时间。重要进程得到的CPU时间多一点，次要进程得到的少一点。确定哪个进程运行多长时间的过程称为调度。\n3.2 UNIX 进程 # Linux对进程采用了一种层次系统，每个进程都依赖于一个父进程。内核启动init程序作为第一个进程，该进程负责进一步的系统初始化操作，并显示登录提示符或图形登录界面（现在使用比较广泛）。因此init是进程树的根，所有进程都直接或间接起源自该进程，如下面的pstree程序的输出所示。其中init是一个树型结构的顶端，而树的分支不断向下扩展。\n该树型结构的扩展方式与新进程的创建方式密切相关。UNIX操作系统中有两种创建新进程的机制，分别是fork和exec。\n(1) fork可以创建当前进程的一个副本，父进程和子进程只有PID（进程ID）不同。在该系统调用执行之后，系统中有两个进程，都执行同样的操作。父进程内存的内容将被复制，至少从程序的角度来看是这样。Linux使用了一种众所周知的技术来使fork操作更高效，该技术称为写时复制（copy on write），主要的原理是将内存复制操作延迟到父进程或子进程向某内存页面写入数据之前，在只读访问的情况下父进程和子进程可以共用同一内存页。\n例如，使用fork的一种可能的情况是，用户打开另一个浏览器窗口。如果选中了对应的选项，浏览器将执行fork，复制其代码，接下来子进程中将启动适当的操作建立新窗口。\n(2) exec将一个新程序加载到当前进程的内存中并执行。旧程序的内存页将刷出，其内容将替换为新的数据。然后开始执行新程序。\n4.内核的特别性 # 5.行文注记 # 6.小结 # ","date":"16 July 2023","permalink":"/linux/book/kernel01/","section":"Linuxes","summary":"最近计划学习 Linux 内核相关内容，Professional Linux Kernel Architecture","title":"深入 Linux 内核架构 01"},{"content":"终于在这个周日的晚上，把这个博客搭建完成了，希望之后可以养成写博客的习惯\n","date":"16 July 2023","permalink":"/diary/daily/","section":"Diaries","summary":"终于在这个周日的晚上，把这个博客搭建完成了，希望之后可以养成写博客的习惯","title":"2023年7月16日"},{"content":"","date":"16 July 2023","permalink":"/tags/diary/","section":"Tags","summary":"","title":"Diary"},{"content":" This is title # 这个包比较简单，就是将文件进行打包和解包，要是熟悉 Linux 下的 tar 命令这个就很好理解了。 主要是通过 tar.Reader 读取 tar 包，通过 tar.Writer 写入 tar 包，在写入的过程中再设置一下头，详细的过程以示例的方式进行展示，可以查看代码里面的注释。\n参考：\n标准库 tar 中文文档\n标准库 tar 官方文档\n单个文件操作 # 这个非常简单，就是读取一个文件，进行打包及解包操作即可。\n单个文件打包 # 从 /etc/passwd 下复制了一个 passwd 文件到当前目录下，用来做压缩测试。什么文件都是可以的，自己随意写一个也行。这里的示例主要为了说明 tar ，没有处理路径，所以过程全部假设是在当前目录下执行。\ncp /etc/passwd . 关于文件的打包直接查看示例代码，已经在示例代码中做了详细的注释。\n示例代码（ pack_single_file.go ）：\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;log\u0026#34; \u0026#34;archive/tar\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; ) func main() { // 准备打包的源文件 var srcFile = \u0026#34;passwd\u0026#34; // 打包后的文件 var desFile = fmt.Sprintf(\u0026#34;%s.tar\u0026#34;,srcFile) // 需要注意文件的打开即关闭的顺序，因为 defer 是后入先出，所以关闭顺序很重要 // 第一次写这个示例的时候就没注意，导致写完的 tar 包不完整 // ###### 第 1 步，先准备好一个 tar.Writer 结构，然后再向里面写入内容。 ###### // 创建一个文件，用来保存打包后的 passwd.tar 文件 fw, err := os.Create(desFile) ErrPrintln(err) defer fw.Close() // 通过 fw 创建一个 tar.Writer tw := tar.NewWriter(fw) // 这里不要忘记关闭，如果不能成功关闭会造成 tar 包不完整 // 所以这里在关闭的同时进行判断，可以清楚的知道是否成功关闭 defer func() { if err := tw.Close(); err != nil { ErrPrintln(err) } }() // ###### 第 2 步，处理文件信息，也就是 tar.Header 相关的 ###### // tar 包共有两部分内容：文件信息和文件数据 // 通过 Stat 获取 FileInfo，然后通过 FileInfoHeader 得到 hdr tar.*Header fi, err := os.Stat(srcFile) ErrPrintln(err) hdr, err := tar.FileInfoHeader(fi, \u0026#34;\u0026#34;) // 将 tar 的文件信息 hdr 写入到 tw err = tw.WriteHeader(hdr) ErrPrintln(err) // 将文件数据写入 // 打开准备写入的文件 fr, err := os.Open(srcFile) ErrPrintln(err) defer fr.Close() written, err := io.Copy(tw, fr) ErrPrintln(err) log.Printf(\u0026#34;共写入了 %d 个字符的数据\\n\u0026#34;,written) } // 定义一个用来打印的函数，少写点代码，因为要处理很多次的 err // 后面其他示例还会继续使用这个函数，就不单独再写，望看到此函数了解 func ErrPrintln(err error) { if err != nil { log.Println(err) os.Exit(1) } } 单个文件解包 # 这个也很简单，基本上将上面过程反过来，只需要处理 tar.Reader 即可，详细的描述见示例。\n这里就用刚刚打包的 passwd.tar 文件做示例，如果怕结果看不出效果，可以将之前用的 passwd 源文件删除。\nrm passwd 示例代码（ unpack_single_file.go ）：\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;archive/tar\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; ) func main() { var srcFile = \u0026#34;passwd.tar\u0026#34; // 将 tar 包打开 fr, err := os.Open(srcFile) ErrPrintln(err) defer fr.Close() // 通过 fr 创建一个 tar.*Reader 结构，然后将 tr 遍历，并将数据保存到磁盘中 tr := tar.NewReader(fr) for hdr, err := tr.Next(); err != io.EOF; hdr, err = tr.Next(){ // 处理 err ！= nil 的情况 ErrPrintln(err) // 获取文件信息 fi := hdr.FileInfo() // 创建一个空文件，用来写入解包后的数据 fw, err := os.Create(fi.Name()) ErrPrintln(err) // 将 tr 写入到 fw n, err := io.Copy(fw, tr) ErrPrintln(err) log.Printf(\u0026#34;解包： %s 到 %s ，共处理了 %d 个字符的数据。\u0026#34;, srcFile,fi.Name(),n) // 设置文件权限，这样可以保证和原始文件权限相同，如果不设置，会根据当前系统的 umask 来设置。 os.Chmod(fi.Name(),fi.Mode().Perm()) // 注意，因为是在循环中，所以就没有使用 defer 关闭文件 // 如果想使用 defer 的话，可以将文件写入的步骤单独封装在一个函数中即可 fw.Close() } } func ErrPrintln(err error){ if err != nil { log.Fatalln(err) os.Exit(1) } } 操作整个目录 # 我们实际中 tar 很少会去打包单个文件，一般都是打包整个目录，并且打包的时候通过 gzip 或者 bzip2 压缩。\n如果要打包整个目录，可以通过递归的方式来实现。这里只演示了 gzip 方式压缩，这个实现非常简单，只需要在 fw 和 tw 之前加上一层压缩即可，详情见示例代码。\n为了测试打包整个目录，复制了一个 log 目录到当前路径下。什么目录和文件都可以，只是因为这个里面内容比较多，就拿这个来做测试了。\n# 出现没有权限的错误不用管它，复制过来多少是多少吧 cp -r /var/log/ . 详细的操作会在注释中说明，不过在之前单文件中出现过的步骤不再注释。\n打包压缩 # 示例代码（ targz.go ）：\npackage main import ( \u0026#34;archive/tar\u0026#34; \u0026#34;compress/gzip\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // 修改日志格式，显示出错代码的所在行，方便调试，实际项目中一般不记录这个。 var src = \u0026#34;apt\u0026#34; var dst = fmt.Sprintf(\u0026#34;%s.tar.gz\u0026#34;, src) // 将步骤写入了一个函数中，这样处理错误方便一些 if err := Tar(src, dst); err != nil { log.Fatalln(err) } } func Tar(src, dst string) (err error) { // 创建文件 fw, err := os.Create(dst) if err != nil { return } defer fw.Close() // 将 tar 包使用 gzip 压缩，其实添加压缩功能很简单， // 只需要在 fw 和 tw 之前加上一层压缩就行了，和 Linux 的管道的感觉类似 gw := gzip.NewWriter(fw) defer gw.Close() // 创建 Tar.Writer 结构 tw := tar.NewWriter(gw) // 如果需要启用 gzip 将上面代码注释，换成下面的 defer tw.Close() // 下面就该开始处理数据了，这里的思路就是递归处理目录及目录下的所有文件和目录 // 这里可以自己写个递归来处理，不过 Golang 提供了 filepath.Walk 函数，可以很方便的做这个事情 // 直接将这个函数的处理结果返回就行，需要传给它一个源文件或目录，它就可以自己去处理 // 我们就只需要去实现我们自己的 打包逻辑即可，不需要再去路径相关的事情 return filepath.Walk(src, func(fileName string, fi os.FileInfo, err error) error { // 因为这个闭包会返回个 error ，所以先要处理一下这个 if err != nil { return err } // 这里就不需要我们自己再 os.Stat 了，它已经做好了，我们直接使用 fi 即可 hdr, err := tar.FileInfoHeader(fi, \u0026#34;\u0026#34;) if err != nil { return err } // 这里需要处理下 hdr 中的 Name，因为默认文件的名字是不带路径的， // 打包之后所有文件就会堆在一起，这样就破坏了原本的目录结果 // 例如： 将原本 hdr.Name 的 syslog 替换程 log/syslog // 这个其实也很简单，回调函数的 fileName 字段给我们返回来的就是完整路径的 log/syslog // strings.TrimPrefix 将 fileName 的最左侧的 / 去掉， // 熟悉 Linux 的都知道为什么要去掉这个 hdr.Name = strings.TrimPrefix(fileName, string(filepath.Separator)) // 写入文件信息 if err := tw.WriteHeader(hdr); err != nil { return err } // 判断下文件是否是标准文件，如果不是就不处理了， // 如： 目录，这里就只记录了文件信息，不会执行下面的 copy if !fi.Mode().IsRegular() { return nil } // 打开文件 fr, err := os.Open(fileName) defer fr.Close() if err != nil { return err } // copy 文件数据到 tw n, err := io.Copy(tw, fr) if err != nil { return err } // 记录下过程，这个可以不记录，这个看需要，这样可以看到打包的过程 log.Printf(\u0026#34;成功打包 %s ，共写入了 %d 字节的数据\\n\u0026#34;, fileName, n) return nil }) } 打包及压缩就搞定了，不过这个代码现在我还发现有个问题，就是不能处理软链接\n解包解压 # 这个过程基本就是把压缩的过程返回来，多了些创建目录的操作\npackage main import ( \u0026#34;archive/tar\u0026#34; \u0026#34;compress/gzip\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; ) func main() { var dst = \u0026#34;\u0026#34; // 不写就是解压到当前目录 var src = \u0026#34;log.tar.gz\u0026#34; UnTar(dst, src) } func UnTar(dst, src string) (err error) { // 打开准备解压的 tar 包 fr, err := os.Open(src) if err != nil { return } defer fr.Close() // 将打开的文件先解压 gr, err := gzip.NewReader(fr) if err != nil { return } defer gr.Close() // 通过 gr 创建 tar.Reader tr := tar.NewReader(gr) // 现在已经获得了 tar.Reader 结构了，只需要循环里面的数据写入文件就可以了 for { hdr, err := tr.Next() switch { case err == io.EOF: return nil case err != nil: return err case hdr == nil: continue } // 处理下保存路径，将要保存的目录加上 header 中的 Name // 这个变量保存的有可能是目录，有可能是文件，所以就叫 FileDir 了…… dstFileDir := filepath.Join(dst, hdr.Name) // 根据 header 的 Typeflag 字段，判断文件的类型 switch hdr.Typeflag { case tar.TypeDir: // 如果是目录时候，创建目录 // 判断下目录是否存在，不存在就创建 if b := ExistDir(dstFileDir); !b { // 使用 MkdirAll 不使用 Mkdir ，就类似 Linux 终端下的 mkdir -p， // 可以递归创建每一级目录 if err := os.MkdirAll(dstFileDir, 0775); err != nil { return err } } case tar.TypeReg: // 如果是文件就写入到磁盘 // 创建一个可以读写的文件，权限就使用 header 中记录的权限 // 因为操作系统的 FileMode 是 int32 类型的，hdr 中的是 int64，所以转换下 file, err := os.OpenFile(dstFileDir, os.O_CREATE|os.O_RDWR, os.FileMode(hdr.Mode)) if err != nil { return err } n, err := io.Copy(file, tr) if err != nil { return err } // 将解压结果输出显示 fmt.Printf(\u0026#34;成功解压： %s , 共处理了 %d 个字符\\n\u0026#34;, dstFileDir, n) // 不要忘记关闭打开的文件，因为它是在 for 循环中，不能使用 defer // 如果想使用 defer 就放在一个单独的函数中 file.Close() } } return nil } // 判断目录是否存在 func ExistDir(dirname string) bool { fi, err := os.Stat(dirname) return (err == nil || os.IsExist(err)) \u0026amp;\u0026amp; fi.IsDir() } 到这里解压就完成了，只是一个实验代码，还有很多不完善的地方，欢迎提出宝贵的意见。\n","date":"14 July 2023","permalink":"/python/python-blog/","section":"Pythons","summary":"This is title # 这个包比较简单，就是将文件进行打包和解包，要是熟悉 Linux 下的 tar 命令这个就很好理解了。 主要是通过 tar.","title":"Python 博客第一篇"},{"content":"","date":"14 July 2023","permalink":"/python/","section":"Pythons","summary":"","title":"Pythons"},{"content":" This is title # 这个包比较简单，就是将文件进行打包和解包，要是熟悉 Linux 下的 tar 命令这个就很好理解了。 主要是通过 tar.Reader 读取 tar 包，通过 tar.Writer 写入 tar 包，在写入的过程中再设置一下头，详细的过程以示例的方式进行展示，可以查看代码里面的注释。\n参考：\n标准库 tar 中文文档\n标准库 tar 官方文档\n单个文件操作 # 这个非常简单，就是读取一个文件，进行打包及解包操作即可。\n单个文件打包 # 从 /etc/passwd 下复制了一个 passwd 文件到当前目录下，用来做压缩测试。什么文件都是可以的，自己随意写一个也行。这里的示例主要为了说明 tar ，没有处理路径，所以过程全部假设是在当前目录下执行。\ncp /etc/passwd . 关于文件的打包直接查看示例代码，已经在示例代码中做了详细的注释。\n示例代码（ pack_single_file.go ）：\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;log\u0026#34; \u0026#34;archive/tar\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; ) func main() { // 准备打包的源文件 var srcFile = \u0026#34;passwd\u0026#34; // 打包后的文件 var desFile = fmt.Sprintf(\u0026#34;%s.tar\u0026#34;,srcFile) // 需要注意文件的打开即关闭的顺序，因为 defer 是后入先出，所以关闭顺序很重要 // 第一次写这个示例的时候就没注意，导致写完的 tar 包不完整 // ###### 第 1 步，先准备好一个 tar.Writer 结构，然后再向里面写入内容。 ###### // 创建一个文件，用来保存打包后的 passwd.tar 文件 fw, err := os.Create(desFile) ErrPrintln(err) defer fw.Close() // 通过 fw 创建一个 tar.Writer tw := tar.NewWriter(fw) // 这里不要忘记关闭，如果不能成功关闭会造成 tar 包不完整 // 所以这里在关闭的同时进行判断，可以清楚的知道是否成功关闭 defer func() { if err := tw.Close(); err != nil { ErrPrintln(err) } }() // ###### 第 2 步，处理文件信息，也就是 tar.Header 相关的 ###### // tar 包共有两部分内容：文件信息和文件数据 // 通过 Stat 获取 FileInfo，然后通过 FileInfoHeader 得到 hdr tar.*Header fi, err := os.Stat(srcFile) ErrPrintln(err) hdr, err := tar.FileInfoHeader(fi, \u0026#34;\u0026#34;) // 将 tar 的文件信息 hdr 写入到 tw err = tw.WriteHeader(hdr) ErrPrintln(err) // 将文件数据写入 // 打开准备写入的文件 fr, err := os.Open(srcFile) ErrPrintln(err) defer fr.Close() written, err := io.Copy(tw, fr) ErrPrintln(err) log.Printf(\u0026#34;共写入了 %d 个字符的数据\\n\u0026#34;,written) } // 定义一个用来打印的函数，少写点代码，因为要处理很多次的 err // 后面其他示例还会继续使用这个函数，就不单独再写，望看到此函数了解 func ErrPrintln(err error) { if err != nil { log.Println(err) os.Exit(1) } } 单个文件解包 # 这个也很简单，基本上将上面过程反过来，只需要处理 tar.Reader 即可，详细的描述见示例。\n这里就用刚刚打包的 passwd.tar 文件做示例，如果怕结果看不出效果，可以将之前用的 passwd 源文件删除。\nrm passwd 示例代码（ unpack_single_file.go ）：\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;archive/tar\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; ) func main() { var srcFile = \u0026#34;passwd.tar\u0026#34; // 将 tar 包打开 fr, err := os.Open(srcFile) ErrPrintln(err) defer fr.Close() // 通过 fr 创建一个 tar.*Reader 结构，然后将 tr 遍历，并将数据保存到磁盘中 tr := tar.NewReader(fr) for hdr, err := tr.Next(); err != io.EOF; hdr, err = tr.Next(){ // 处理 err ！= nil 的情况 ErrPrintln(err) // 获取文件信息 fi := hdr.FileInfo() // 创建一个空文件，用来写入解包后的数据 fw, err := os.Create(fi.Name()) ErrPrintln(err) // 将 tr 写入到 fw n, err := io.Copy(fw, tr) ErrPrintln(err) log.Printf(\u0026#34;解包： %s 到 %s ，共处理了 %d 个字符的数据。\u0026#34;, srcFile,fi.Name(),n) // 设置文件权限，这样可以保证和原始文件权限相同，如果不设置，会根据当前系统的 umask 来设置。 os.Chmod(fi.Name(),fi.Mode().Perm()) // 注意，因为是在循环中，所以就没有使用 defer 关闭文件 // 如果想使用 defer 的话，可以将文件写入的步骤单独封装在一个函数中即可 fw.Close() } } func ErrPrintln(err error){ if err != nil { log.Fatalln(err) os.Exit(1) } } 操作整个目录 # 我们实际中 tar 很少会去打包单个文件，一般都是打包整个目录，并且打包的时候通过 gzip 或者 bzip2 压缩。\n如果要打包整个目录，可以通过递归的方式来实现。这里只演示了 gzip 方式压缩，这个实现非常简单，只需要在 fw 和 tw 之前加上一层压缩即可，详情见示例代码。\n为了测试打包整个目录，复制了一个 log 目录到当前路径下。什么目录和文件都可以，只是因为这个里面内容比较多，就拿这个来做测试了。\n# 出现没有权限的错误不用管它，复制过来多少是多少吧 cp -r /var/log/ . 详细的操作会在注释中说明，不过在之前单文件中出现过的步骤不再注释。\n打包压缩 # 示例代码（ targz.go ）：\npackage main import ( \u0026#34;archive/tar\u0026#34; \u0026#34;compress/gzip\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // 修改日志格式，显示出错代码的所在行，方便调试，实际项目中一般不记录这个。 var src = \u0026#34;apt\u0026#34; var dst = fmt.Sprintf(\u0026#34;%s.tar.gz\u0026#34;, src) // 将步骤写入了一个函数中，这样处理错误方便一些 if err := Tar(src, dst); err != nil { log.Fatalln(err) } } func Tar(src, dst string) (err error) { // 创建文件 fw, err := os.Create(dst) if err != nil { return } defer fw.Close() // 将 tar 包使用 gzip 压缩，其实添加压缩功能很简单， // 只需要在 fw 和 tw 之前加上一层压缩就行了，和 Linux 的管道的感觉类似 gw := gzip.NewWriter(fw) defer gw.Close() // 创建 Tar.Writer 结构 tw := tar.NewWriter(gw) // 如果需要启用 gzip 将上面代码注释，换成下面的 defer tw.Close() // 下面就该开始处理数据了，这里的思路就是递归处理目录及目录下的所有文件和目录 // 这里可以自己写个递归来处理，不过 Golang 提供了 filepath.Walk 函数，可以很方便的做这个事情 // 直接将这个函数的处理结果返回就行，需要传给它一个源文件或目录，它就可以自己去处理 // 我们就只需要去实现我们自己的 打包逻辑即可，不需要再去路径相关的事情 return filepath.Walk(src, func(fileName string, fi os.FileInfo, err error) error { // 因为这个闭包会返回个 error ，所以先要处理一下这个 if err != nil { return err } // 这里就不需要我们自己再 os.Stat 了，它已经做好了，我们直接使用 fi 即可 hdr, err := tar.FileInfoHeader(fi, \u0026#34;\u0026#34;) if err != nil { return err } // 这里需要处理下 hdr 中的 Name，因为默认文件的名字是不带路径的， // 打包之后所有文件就会堆在一起，这样就破坏了原本的目录结果 // 例如： 将原本 hdr.Name 的 syslog 替换程 log/syslog // 这个其实也很简单，回调函数的 fileName 字段给我们返回来的就是完整路径的 log/syslog // strings.TrimPrefix 将 fileName 的最左侧的 / 去掉， // 熟悉 Linux 的都知道为什么要去掉这个 hdr.Name = strings.TrimPrefix(fileName, string(filepath.Separator)) // 写入文件信息 if err := tw.WriteHeader(hdr); err != nil { return err } // 判断下文件是否是标准文件，如果不是就不处理了， // 如： 目录，这里就只记录了文件信息，不会执行下面的 copy if !fi.Mode().IsRegular() { return nil } // 打开文件 fr, err := os.Open(fileName) defer fr.Close() if err != nil { return err } // copy 文件数据到 tw n, err := io.Copy(tw, fr) if err != nil { return err } // 记录下过程，这个可以不记录，这个看需要，这样可以看到打包的过程 log.Printf(\u0026#34;成功打包 %s ，共写入了 %d 字节的数据\\n\u0026#34;, fileName, n) return nil }) } 打包及压缩就搞定了，不过这个代码现在我还发现有个问题，就是不能处理软链接\n解包解压 # 这个过程基本就是把压缩的过程返回来，多了些创建目录的操作\npackage main import ( \u0026#34;archive/tar\u0026#34; \u0026#34;compress/gzip\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; ) func main() { var dst = \u0026#34;\u0026#34; // 不写就是解压到当前目录 var src = \u0026#34;log.tar.gz\u0026#34; UnTar(dst, src) } func UnTar(dst, src string) (err error) { // 打开准备解压的 tar 包 fr, err := os.Open(src) if err != nil { return } defer fr.Close() // 将打开的文件先解压 gr, err := gzip.NewReader(fr) if err != nil { return } defer gr.Close() // 通过 gr 创建 tar.Reader tr := tar.NewReader(gr) // 现在已经获得了 tar.Reader 结构了，只需要循环里面的数据写入文件就可以了 for { hdr, err := tr.Next() switch { case err == io.EOF: return nil case err != nil: return err case hdr == nil: continue } // 处理下保存路径，将要保存的目录加上 header 中的 Name // 这个变量保存的有可能是目录，有可能是文件，所以就叫 FileDir 了…… dstFileDir := filepath.Join(dst, hdr.Name) // 根据 header 的 Typeflag 字段，判断文件的类型 switch hdr.Typeflag { case tar.TypeDir: // 如果是目录时候，创建目录 // 判断下目录是否存在，不存在就创建 if b := ExistDir(dstFileDir); !b { // 使用 MkdirAll 不使用 Mkdir ，就类似 Linux 终端下的 mkdir -p， // 可以递归创建每一级目录 if err := os.MkdirAll(dstFileDir, 0775); err != nil { return err } } case tar.TypeReg: // 如果是文件就写入到磁盘 // 创建一个可以读写的文件，权限就使用 header 中记录的权限 // 因为操作系统的 FileMode 是 int32 类型的，hdr 中的是 int64，所以转换下 file, err := os.OpenFile(dstFileDir, os.O_CREATE|os.O_RDWR, os.FileMode(hdr.Mode)) if err != nil { return err } n, err := io.Copy(file, tr) if err != nil { return err } // 将解压结果输出显示 fmt.Printf(\u0026#34;成功解压： %s , 共处理了 %d 个字符\\n\u0026#34;, dstFileDir, n) // 不要忘记关闭打开的文件，因为它是在 for 循环中，不能使用 defer // 如果想使用 defer 就放在一个单独的函数中 file.Close() } } return nil } // 判断目录是否存在 func ExistDir(dirname string) bool { fi, err := os.Stat(dirname) return (err == nil || os.IsExist(err)) \u0026amp;\u0026amp; fi.IsDir() } 到这里解压就完成了，只是一个实验代码，还有很多不完善的地方，欢迎提出宝贵的意见。\n","date":"12 July 2023","permalink":"/python/tests/","section":"Pythons","summary":"This is title # 这个包比较简单，就是将文件进行打包和解包，要是熟悉 Linux 下的 tar 命令这个就很好理解了。 主要是通过 tar.","title":"First Blog"},{"content":"Go 面经 相关记录\n基础语法 # = 和 := 的区别？ =是赋值变量，:=是定义变量 指针的作用 一个指针可以指向任意变量的地址，它所指向的地址在32位或64位机器上分别固定占4或8个字节。指针的作用有 获取变量的值 改变变量的值 用指针替代值传入函数，比如类的接收器就是这样的 Go 允许多个返回值吗？ 可以。通常函数除了一般返回值还会返回一个error Go 有异常类型吗？ 有。Go用error类型代替try\u0026hellip;catch语句，这样可以节省资源。同时增加代码可读性 也可以用errors.New()来定义自己的异常。errors.Error()会返回异常的字符串表示。只要实现error接口就可以定义自己的异常， 什么是协程（Goroutine） *协程是用户态轻量级线程，它是线程调度的基本单位。通常在函数前加上go关键字就能实现并发。一个Goroutine会以一个很小的栈启动2KB或4KB，当遇到栈空间不足时，栈会自动伸缩， 因此可以轻易实现成千上万个goroutine同时启动 如何高效地拼接字符串 拼接字符串的方式有：+ , fmt.Sprintf , strings.Builder, bytes.Buffer, strings.Join 使用+操作符进行拼接时，会对字符串进行遍历，计算并开辟一个新的空间来存储原来的两个字符串由于采用了接口参数，必须要用反射获取值，因此有性能损耗 用WriteString()进行拼接，内部实现是指针+切片，同时String()返回拼接后的字符串，它是直接把[]byte转换为string，从而避免变量拷贝 bytes.Buffer是一个一个缓冲byte类型的缓冲器，这个缓冲器里存放着都是byte,bytes.buffer底层也是一个[]byte切片 strings.join也是基于strings.builder来实现的,并且可以自定义分隔符，在join方法内调用了b.Grow(n)方法，这个是进行初步的容量分配，而前面计算的n的长度就是我们要拼接的slice的长度，因为我们传入切片长度固定，所以提前进行容量分配可以减少内存分配，很高效 性能比较：strings.Join ≈ strings.Builder \u0026gt; bytes.Buffer \u0026gt; \u0026ldquo;+\u0026rdquo; \u0026gt; fmt.Sprintf 什么是 rune 类型 如何判断 map 中是否包含某个 key ？ Go 支持默认参数或可选参数吗？ defer 的执行顺序 如何交换 2 个变量的值？ Go 语言 tag 的用处？ 如何判断 2 个字符串切片（slice) 是相等的？ 字符串打印时，%v 和 %+v 的区别 Go 语言中如何表示枚举值(enums)？ 空 struct{} 的用途 实现原理 # init() 函数是什么时候执行的 Go 语言的局部变量分配在栈上还是堆上？ 2 个 interface 可以比较吗 ？ 2 个 nil 可能不相等吗？ 简述 Go 语言GC(垃圾回收)的工作原理 函数返回局部变量的指针是否安全？ 非接口非接口的任意类型 T() 都能够调用 *T 的方法吗？反过来呢？ 并发编程 # 无缓冲的 channel 和有缓冲的 channel 的区别？ 什么是协程泄露(Goroutine Leak)？ Go 可以限制运行时操作系统线程的数量吗？ 代码输出 # 变量与常量 作用域 defer 延迟调用 ","date":"11 July 2023","permalink":"/golang/interview/problems/","section":"Golang","summary":"Go 面经 相关记录","title":"Go 面试题"},{"content":"","date":"23 July 2022","permalink":"/tags/template/","section":"Tags","summary":"","title":"Template"},{"content":"仅作为日志模板\n","date":"23 July 2022","permalink":"/diary/template/","section":"Diaries","summary":"仅作为日志模板","title":"模板日志"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"1 January 0001","permalink":"/series/","section":"Series","summary":"","title":"Series"}]