[{"content":"","date":"23 July 2023","permalink":"/diary/","section":"Diaries","summary":"","title":"Diaries"},{"content":"","date":"23 July 2023","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"23 July 2023","permalink":"/tags/update/","section":"Tags","summary":"","title":"Update"},{"content":"Less can be more.\n","date":"23 July 2023","permalink":"/","section":"Welcome to NewtSun","summary":"Less can be more.","title":"Welcome to NewtSun"},{"content":"Blog 更新日志\n2023.07.23 # Update Linux、Diary、Golang 2023.07.15 # First Commit ","date":"23 July 2023","permalink":"/diary/update/","section":"Diaries","summary":"Blog 更新日志","title":"更新日志"},{"content":"","date":"22 July 2023","permalink":"/tags/commands/","section":"Tags","summary":"","title":"Commands"},{"content":"总结常用的 Linux 系统命令\n安装 sudo dpkg -i package_name.deb 复制 sudo cp -r ~/下载/jbr jbr 删除 sudo rm -r Goland-2023.1.2/ 查看进程并过滤所需的端口 netstat -anp | grep 5678 查看 lsof -i：5678 删除 kill -9 174189 goland 安装 sudo tar -C /usr/local -xzf goland-2020.3.4.tar.gz hostname hostname -I df 查看当前系统中挂载的文件系统类型、各文件系统 inode 使用情况及文件系统挂载点 df -i --print-type ","date":"22 July 2023","permalink":"/linux/learn/commands/","section":"Linuxes","summary":"总结常用的 Linux 系统命令","title":"Linux 常用命令"},{"content":"","date":"22 July 2023","permalink":"/linux/","section":"Linuxes","summary":"","title":"Linuxes"},{"content":"把之前写的一些面经逐渐迁移过来了\u0026hellip;\n1.原子操作 # 原子操作的意思是说，这个操作在执行的过程中，其它协程不会看到执行一半的操作结果。\n在单处理器单核系统中，即使一个操作翻译成汇编不止一个指令，也有可能保持一致性。比如经常用来演示的并发场景下的 count++ 操作 （count++ 对应的汇编指令就有三条），如果像下面这样写：\nfunc main() { runtime.GOMAXPROCS(1) var w sync.WaitGroup count := int32(0) w.Add(100) for i := 0; i \u0026lt; 100; i++ { go func() { for j := 0; j \u0026lt; 20; j++ { count++ } w.Done() }() } w.Wait() fmt.Println(count) } 而在多核系统中，情况就变得复杂了许多。A核修改 count 的时候，由于 CPU 缓存的存在，B核读到的 count 值可能不是最新的值。如果我们将上面的例子中的第二行改成：\nruntime.GOMAXPROCS(2) 之后，程序每执行一次，结果都有可能不一样。\n解决思路除了使用前面介绍过的 Mutex，也可以使用今天要介绍的 atomic，具体使用方法是将 count++ 替换成：\natomic.AddInt32(\u0026amp;count, 1) 这样就能保证即使在多核系统下 count++ 也是一个原子操作。\n针对一些基本的原子操作，不同的 CPU 架构中有不同的机制来保证原子性，atomic 包将底层不同架构的实现进行了封装，对外提供通用的 API。\natomic 的基础方法：\n原子操作主要是两类：修改和加载存储。修改很好理解，就是在原来值的基础上改动；加载存储就是读写。\natomic 提供了 AddXXX、CompareAndSwapXXX、SwapXXX、LoadXXX、StoreXXX 等方法。\n需要注意的是，atomic 的操作对象是地址，所以传参的时候，需要传变量的地址，不能传变量的值。\n来源： https://zhuanlan.zhihu.com/p/359971105\n2.Map 的底层实现 # 底层是 hmap 结构体，通过调用runtime.makemap函数，主要工作就是初始化 hmap 结构体的各个字段，hmap 里维护着若干个 bucket 数组 (即桶数组)，bucket 数组中每个元素都是 bmap 结构，也即每个bucket（桶）都是bmap结构，每个桶中保存了8个kv对，如果8个满了，会使用 overflow 连接下一个桶(溢出桶)。\n计算 key 的hash值 通过最后的“B”位来确定在哪号桶，如果B为4，所以取 key 对应哈希值的后4位 根据 key 对应的 hash 值前8位快速确定是在这个桶的哪个位置（tophash） 对比key完整的hash是否匹配，如果匹配则获取对应value 如果都没有找到，就去连接的下一个溢出桶中找 扩容方式：\n相同容量扩容（元素会发生重排，但不会换桶） 2倍容量扩容（元素会重排，可能会发生桶迁移） type hmap struct { count int // 元素的个数 B uint8 // buckets 数组的长度就是 2^B 个 overflow uint16 // 溢出桶的数量 buckets unsafe.Pointer // 2^B个桶对应的数组指针 oldbuckets unsafe.Pointer // 发生扩容时，记录扩容前的buckets数组指针 extra *mapextra //用于保存溢出桶的地址 } type mapextra struct { overflow *[]*bmap oldoverflow *[]*bmap nextOverflow *bmap } type bmap struct { tophash [bucketCnt]uint8 } //在编译期间会产生新的结构体 type bmap struct { tophash [8]uint8 //存储哈希值的高8位 data byte[1] //key value数据:key/key/key/.../value/value/value... overflow *bmap //溢出bucket的地址 } 3.sync.Map 的底层实现 # sync.Map 的设计利用了 atmoic 和 mutex 的配合：\n使用了两个原生的 map 作为存储介质，分别是 read map 和 dirty map（只读字典和脏字典）。 只读字典使用 atomic.Value 来承载，保证原子性和高性能；脏字典则需要用互斥锁来保护，保证了互斥。 只读字典和脏字典中的键值对集合并不是实时同步的，它们在某些时间段内可能会有不同。 无论是 read 还是 dirty，本质上都是 *map[interface{}]entry 类型，这里的 entry 其实就是 Map 的 value 的容器。 entry 的本质，是一层封装，可以表示具体值的指针，也可以表示 key 已删除的状态（即逻辑假删除） 通过这种设计，规避了原生 map 无法并发安全 delete 的问题，同时在变更某个键所对应的值的时候，就也可以使用原子操作了\n4.goroutine 的原理 # 基于CSP并发模型开发了GMP调度器：\n1.G：是Goroutine的缩写，是Goroutine的控制结构，对 Goroutine 的抽象。其中包括执行的函数指令及参数；G 保存的任务对象；线程上下文切换，现场保护和现场恢复需要的寄存器(SP、IP)等信息。在 Go 语言中使用 runtime.g 结构表示。\n2.M：是内核线程，由操作系统调度以及管理，调度器最多可以创建 10000 个线程，在 Go 语言中使用 runtime.m 结构表示。（用户线程与内核线程的映射关系）\n3.P：是调度各个goroutine，使他们之间协调运行的逻辑处理器，但不代表真正的CPU的数量，真正决定并发程度的是P，初始化的时候一般会去读取GOMAXPROCS对应的值，如果没有显示设置，则会读取默认值，在Go1.5之后GOMAXPROCS被默认设置可用的核数，而之前则默认为1，在 Go 语言中使用 runtime.p 结构表示。\n4.指定cpu线程个数\n通过runtime.GOMAXPROCS()，可以指定P的个数,如果没有指定则默认跑满整个cpu\n5.GMP 调度模型 # goroutine 的调度是 Go 语言运行时（runtime）层面的实现，由 Go 语言本身实现的一套调度系统：go scheduler。是按照一定的规则将所有的 goroutine 调度到操作系统线程上执行。目前 Go 语言的调度器采用的是 GPM 调度模型。\nG：表示 goroutine，每执行一次go f()就创建一个 G，包含要执行的函数和上下文信息 全局队列（Global Queue）：存放等待运行的 G P：是调度各个goroutine，使他们之间协调运行的逻辑处理器，表示 goroutine 执行所需的资源，最多有 GOMAXPROCS 个 P 的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建 G 时，G 优先加入到 P 的本地队列，如果本地队列满了会批量移动部分 G 到全局队列 M：是内核线程，由操作系统调度以及管理，线程想运行任务就得获取 P，从 P 的本地队列获取 G，当 P 的本地队列为空时，M 也会尝试从全局队列或其他 P 的本地队列获取 G。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去 Goroutine 调度器和操作系统调度器是通过 M 结合起来的，每个 M 都代表了1个内核线程，操作系统调度器负责把内核线程分配到 CPU 的核上执行 调度器的设计策略：\n复用线程：避免频繁的创建、销毁线程，而是对线程的复用\nwork stealing 机制：当本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程 hand off 机制：当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行 利用并行：GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个CPU上同时运行，GOMAXPROCS也限制了并发的程度，比如GOMAXPROCS = 核数/2，则最多利用了一半的CPU核进行并行\n抢占：在 coroutine 中要等待一个协程主动让出CPU才执行下一个协程，在Go中，一个goroutine最多占用CPU 10ms，防止其他goroutine被饿死，这就是goroutine不同于coroutine的一个地方\n全局G队列：在新的调度器中依然有全局G队列，但功能已经被弱化了，当M执行work stealing从其他P偷不到G时，它可以从全局G队列获取G\n6.channel 的底层实现 # channel 的操作封装在 runtime 包下的 chan.go 文件\ntype hchan struct { qcount uint // channel中环形队列数据总数，len()返回该值 dataqsiz uint // 环形队列的长度，make时指定，cap()返回该值 buf unsafe.Pointer // 指向环形队列的指针，缓存区基于环形队列实现 elemsize uint16 // 元素的大小 closed uint32 // channel关闭标志 elemtype *_type // 元素类型 sendx uint // 向channel发送数据时，写入的位置索引 recvx uint // 从channel读数据时，读取的位置索引 recvq waitq // buf空时，读取的goroutine等待队列 sendq waitq // buf满时，写入的goroutine等待队列 // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G\u0026#39;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex // 并发控制锁，同一时刻，只允许一个 } // 等待goroutine的双向链表结构 type waitq struct { first *sudog last *sudog } 7.unsafe.Pointer 的使用 # 7.1 使用 unsafe.Pointer 做类型转换 # 可以简洁适宜的转换两个在内存中结构一样的类型是使用 unsafe.Pointer 的一个主要原因。\n文档描述：\n如果T2与T1一样大，并且两者有相同的内存结构；那么就允许把一个类型的数据，重新定义成另一个类型的数据\n经典的例子，是文档中的一次使用，用来实现 math.Float64bits：\nfunc Float64bits(f float64) uint64 { return *(*uint64)(unsafe.Pointer(\u0026amp;f)) } 这似乎是一种非常简洁的完成这样转换的方法，但是这个过程中具体发生了什么？让我们一步步拆分一下：\n\u0026amp;f 拿到一个指向 f 存放 float64 值的指针。 unsafe.Pointer(\u0026amp;f) 将 *float64 类型转化成了 unsafe.Pointer 类型。 (uint64)(unsafe.Pointer(\u0026amp;f)) 将 unsafe.Pointer 类型转化成了 uint64。 _(_uint64)(unsafe.Pointer(\u0026amp;f)) 引用这个 *uint64 类型指针，转化为一个 uint64 类型的值。 第一个例子是下面过程的一个简洁表达：\nfunc Float64bits(floatVal float64) uint64 { // 获取一个指向存储这个float64类型值的指针。 floatPtr := \u0026amp;floatVal // 转化*float64类型到unsafe.Pointer类型。 unsafePtr := unsafe.Pointer(floatPtr) // 转化unsafe.Pointer类型到*uint64类型. uintPtr := (*uint64)(unsafePtr) // 解引用成一个uint64值 uintVal := *uintPtr return uintVal } 7.2 使用 unsafe.Pointer 处理系统调用 # 当处理系统调用时，有些时候需要传入一个指向某块内存的指针给内核，以允许它执行某些任务。这是 unsafe.Pointer 在 Go 中另一个重要的使用场景。当需要处理系统调用时，就必须使用 unsafe.Pointer，因为为了使用 syscall.Syscall 家族函数，它可以被转化成 uintptr 类型。\n对于许多不同的操作系统，都拥有大量的系统调用。但是在这个例子中，我们将重点关注 ioctl 。ioctl，在UNIX类系统中，经常被用来操作那些无法直接映射到典型的文件系统操作，例如读和写的文件描述符。事实上，由于 ioctl 系统调用十分灵活，它并不在Go的 syscall 或者 x/sys/unix 包中。\n让我看看另一个真实的例子。\n现实例子：ioctl / vsock\n在过去的几年里，Linux 增加了一个新的 socket 家族，AF_VSOCK，它可以使管理中心和它的虚拟机之间双向，多对一的通信。 这些套接字使用一个上下文 ID 进行通信。通过发送一个带有特殊请求号的 ioctl 到 /dev/vsock 驱动，可以取到这个上下文 ID。\n下面是 ioctl 函数的定义：\nfunc Ioctl(fd uintptr, request int, argp unsafe.Pointer) error { _, _, errno := unix.Syscall( unix.SYS_IOCTL, fd, uintptr(request), // 在这个调用表达式中，从 unsafe.Pointer 到 uintptr 的转换是必须做的。详情可以查看 unsafe 包的文档 uintptr(argp), ) if errno != 0 { return os.NewSyscallError(\u0026#34;ioctl\u0026#34;, fmt.Errorf(\u0026#34;%d\u0026#34;, int(errno))) } return nil } 像代码注释所写一样，在这种场景下使用 unsafe.Pointer 有一个很重要的说明：\n在 syscall 包中的系统调用函数通过它们的 uintptr 类型参数直接操作系统，然后根据调用的详细情况，将它们中的一些转化为指针。换句话说，系统调用的执行，是其中某些参数从 uintptr 类型到指针类型的隐式转换。 如果一个指针参数必须转换成 uintptr 才能使用，那么这种转换必须出现在表达式内部。\n但是为什么会这样？这是编译器识别的特殊模式，本质上是指示垃圾收集器在函数调用完成之前，不能将被指针引用的内存再次安排。\n你可以通过阅读文档来获得更多的技术细节，但是你在Go中处理系统调用时必须记住这个规则。事实上，在写这篇文章时，我意识到我的代码违反了这一规则，现在已经被修复了。\n意识到这一点，我们可以看到这个函数是如何使用的。\n在 VM 套接字的例子里，我们想传递一个 *uint32 到内核，以便它可以把我们当时的上下文ID赋值到这块内存地址中。\nf, err := fs.Open(\u0026#34;/dev/vsock\u0026#34;) if err != nil { return 0, err } defer f.Close() // 存储上下文ID var cid uint32 // 从这台机器的 /dev/vsock 中获取上下文ID err = Ioctl(f.Fd(), unix.IOCTL_VM_SOCKETS_GET_LOCAL_CID, unsafe.Pointer(\u0026amp;cid)) if err != nil { return 0, err } // 返回当前的上下文ID给调用者 return cid, nil 这只是在系统调用时使用 unsafe.Pointer 的一个例子。你可以使用这么模式发送、接收任何数据，或者是用一些特殊方式配置一个内核接口。有很多可能的情况\n","date":"22 July 2023","permalink":"/golang/interview/ed/","section":"Golangs","summary":"把之前写的一些面经逐渐迁移过来了\u0026hellip;","title":"Go 面经"},{"content":"","date":"22 July 2023","permalink":"/golang/","section":"Golangs","summary":"","title":"Golangs"},{"content":"","date":"22 July 2023","permalink":"/tags/interview/","section":"Tags","summary":"","title":"Interview"},{"content":"","date":"22 July 2023","permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux"},{"content":"文件系统\n1.文件系统 # 任何技术的出现是为了解决问题，文件系统也是为了解决某些问题。那文件系统是为了解决什么问题呢？\n我们有了一个相对形象的概念，文件系统管理着很多文件。而这些文件其实就是数据，这些数据又是存储在磁盘上的。因此，实质上文件系统是管理磁盘的软件系统，它简化了用户对磁盘空间的使用方法，并降低了磁盘空间的使用难度，通过更加形象的方式将磁盘中的数据展示给用户。 赵二狗窃窃私语：“好啰嗦” 大家对磁盘都比较清楚，其实就是存储数据的地方，我们可以将磁盘与仓库类比。类似一个空仓库，一个没有格式化的磁盘就好像一个空仓库，空间非常大，我们可以随便使用。\n磁盘的内部虽然非常复杂，但磁盘生产厂商做了很多工作，将磁盘的复杂性掩盖起来了。对于普通用户来说，磁盘就是一个线性空间，就好像C语言中的数组一样，通过偏移就可以访问其空间（读写数据）。\n但是，我们虽然可以直接访问磁盘的空间，如果缺乏规划，那么使用的最终结果可能是这样样子的。数据被毫无规律的放到磁盘上，最后查找的时候会非常费劲，甚至可能找不到需要的数据。\n因此，文件系统出现了。文件系统实现对磁盘空间的统一管理，一方面文件系统对磁盘空间进行统一规划，另外一方面文件系统提供给普通用户人性化的接口。就好比仓库中的货架，将空间进行规划和编排，这样根据编号可以方便的找到具体的货物。而文件系统也是类似，将磁盘空间进行规划和编号处理，这样通过文件名就可以找到具体的数据，而不用关心数据到底是怎么存储的。\n以Ext4文件系统为例，它将磁盘空间进行划分，并通过元数据实现对磁盘空间的管理。这样，用户对文件的操作就转化为文件系统对磁盘空间的操作。 也就是说，文件系统解决了普通用户使用磁盘存储数据的问题。\n2.分布式文件系统 # 上面说的是普通本地文件系统的概念，比如Ext4、XFS、FAT32和Btrfs等文件系统。这些文件系统只能在本地进行磁盘格式化并使用。那么什么是分布式文件系统呢？下面是维基百科给出的定义。\n相对于本机端的文件系统而言，分布式文件系统（英语：Distributed file system, DFS），或是网络文件系统（英语：Network File System），是一种允许文件透过网络在多台主机上分享的文件系统，可让多机器上的多用户分享文件和存储空间。\n通过定义我肯可以看出，分布式文件系统解决的是资源共享的问题。我们先看一个实例，以NFS文件系统为例，它分为服务端和客户端，客户端通过某种协议连接到服务端，此时会在客户端的目录树中映射一个子树，这样在客户端就能访问服务端的文件系统。然而，对于客户端来说，这个目录树关系是透明的，也就是用户不知道这些内容是在远程计算机，也不用关心。\n分布式文件系统解决的最大的问题是资源共享的问题，因此分布式文件系统最大的特点是多个客户端可以访问相同的服务端。\n图 NFS可以供多个客户端访问，但其毕竟是单机，处理能力是有限的。因此在大规模数据领域，不如电商网站、大数据处理等，采用单机模式无法满足要求。问题有出来了，为了解决这个问题，谷歌开发了GFS分布式文件系统，该文件系统的服务端通过一个集群来实现，客户端可以并发的访问该集群的多达数万个节点，因此承载能力得到极大的提升。 如图10是HDFS的架构图，HDFS是GFS的开源实现，起基本架构是一样的。整个集群的节点分为2中角色，一个是Master节点，负责管理元数据；另外一个是数据节点，负责存储文件的数据。在这种架构中，客户端通过Master节点可以得到文件数据的具体位置，然后可以直接与数据节点交互。由于数据节点可以很多（数万个），因此承载能力得到极大的提升。\n除了上述HDFS和GFS等分布式文件系统外，还有GlusterFS、CephFS等很多分布式文件系统，但每种分布式文件系统的细节又有所差异，这个也是与它们所要解决的具体问题相关的。\n3.集群文件系统 # 虽然分布式文件系统可以处理高并发访问的问题，但对于同一个文件同时写会存在数据不一致的问题。这个需要客户端的应用做特殊处理。如图11所示，客户端1从服务端读取的某个文件的数据，而此时在客户端进行了追加写操作，由于网络延迟或者什么原因，数据并没有达到服务端。此时，客户端2读取了服务端的数据，显然此时数据是旧数据。如果此时客户端2进行写操作，无法保证服务端最终的数据是客户端1的还是客户端2的，因此存在不可预料的结果。\n为了解决同一个文件被不同客户端的应用并发写的问题，这个时候开发了集群文件系统。其中比较著名的是Oracle的OCFS2文件系统。OCFS2通过分布式锁解决了写并发的问题，如果有进程对某个文件的区域进行写操作时会加锁，这样其它客户端如果对相同区域写数据时就必须等待。这样，OCFS2文件系统就保证了数据的一致性。 到此为止，我们介绍文件系统的原理及市面上常见的各种类型的文件系统。通过分析我们看到，不同的文件系统解决的问题是不同的，因此应用场景也是有很大差异的。因此，大家在工作中如果选型时，也需要考虑这些差异。\n","date":"22 July 2023","permalink":"/linux/learn/file-system/","section":"Linuxes","summary":"文件系统","title":"文件系统"},{"content":"最近计划学习 Linux 内核相关内容，Professional Linux Kernel Architecture\n第一章：简介及概述 # 1.内核的任务 # 内核是硬件与软件之间的一个中间层，其作用是将应用程序的请求传递给硬件，并充当底层驱动程序，对系统中的各种设备和组件进行寻址。\n从应用程序的视角来看，内核可以被认为是一台增强的计算机，将计算机抽象到一个高层次上。例如，在内核寻址硬盘时，它必须确定使用哪个路径来从磁盘向内存复制数据，数据的位置，经由哪个路径向磁盘发送哪一条命令，等等。另一方面，应用程序只需发出传输数据的命令。实际的工作如何完成与应用程序是不相干的，因为内核抽象了相关的细节。应用程序与硬件本身没有联系，只与内核有联系，内核是应用程序所知道的层次结构中的最底层，因此内核是一台增强的计算机。 当若干程序在同一系统中并发运行时，也可以将内核视为资源管理程序。在这种情况下，内核负责将可用共享资源（包括CPU时间、磁盘空间、网络连接等）分配到各个系统进程，同时还需要保证系统的完整性。 另一种研究内核的视角是将内核视为库，其提供了一组面向系统的命令。通常，系统调用用于向计算机发送请求。借助于C标准库，系统调用对于应用程序就像是普通函数一样，其调用方式与其他函数相同。 2.实现策略 # 微内核：这种范型中，只有最基本的功能直接由中央内核（即微内核）实现。所有其他的功能都委托给一些独立进程，这些进程通过明确定义的通信接口与中心内核通信。例如，独立进程可能负责实现各种文件系统、内存管理等。（当然，与系统本身的通信需要用到最基本的内存管理功能，这是由微内核实现的。但系统调用层次上的处理则由外部的服务器进程实现。）理论上，这是一种很完美的方法，因为系统的各个部分彼此都很清楚地划分开来，同时也迫使程序员使用“清洁的”程序设计技术。这种方法的其他好处包括：动态可扩展性和在运行时切换重要组件。但由于在各个组件之间支持复杂通信需要额外的CPU时间，所以尽管微内核在各种研究领域早已经成为活跃主题，但在实用性方面进展甚微。 宏内核：：与微内核相反，宏内核是构建系统内核的传统方法。在这种方法中，内核的全部代码，包括所有子系统（如内存管理、文件系统、设备驱动程序）都打包到一个文件中。内核中的每个函数都可以访问内核中所有其他部分。如果编程时不小心，很可能会导致源代码中出现复杂的嵌套。 因为在目前，宏内核的性能仍然强于微内核，Linux仍然是依据这种范型实现的（以前亦如此）。\n3.内核的组成部分 # Linux 是整体式的宏内核：\n图1 内核的组成部分 3.1 进程、进程切换、调度 # 各个进程的地址空间是完全独立的，因此进程并不会意识到彼此的存在，从进程的角度来看，它会任务自己是系统中唯一的进程。如果进程想要彼此通信（例如交换数据），那么必须使用特定的内核机制。\n由于 Linux 是多任务系统，它支持（看上去）并发执行的若干进程。系统中真正在运行的进程数目最多不超过CPU数目，因此内核会按照短的时间间隔在不同的进程之间切换（用户是注意不到 的），这样就造成了同时处理多进程的假象。\n(1) 内核借助于CPU的帮助，负责进程切换的技术细节。必须给各个进程造成一种错觉，即CPU总是可用的。通过在撤销进程的CPU资源之前保存进程所有与状态相关的要素，并将进程置于空闲状态，即可达到这一目的。在重新激活进程时，则将保存的状态原样恢复。进程之间的切换称之为进程切换。\n(2) 内核还必须确定如何在现存进程之间共享CPU时间。重要进程得到的CPU时间多一点，次要进程得到的少一点。确定哪个进程运行多长时间的过程称为调度。\n3.2 UNIX 进程 # Linux对进程采用了一种层次系统，每个进程都依赖于一个父进程。内核启动init程序作为第一个进程，该进程负责进一步的系统初始化操作，并显示登录提示符或图形登录界面（现在使用比较广泛）。因此init是进程树的根，所有进程都直接或间接起源自该进程，如下面的pstree程序的输出所示。其中init是一个树型结构的顶端，而树的分支不断向下扩展。\n该树型结构的扩展方式与新进程的创建方式密切相关。UNIX操作系统中有两种创建新进程的机制，分别是fork和exec。\n(1) fork可以创建当前进程的一个副本，父进程和子进程只有PID（进程ID）不同。在该系统调用执行之后，系统中有两个进程，都执行同样的操作。父进程内存的内容将被复制，至少从程序的角度来看是这样。Linux使用了一种众所周知的技术来使fork操作更高效，该技术称为写时复制（copy on write），主要的原理是将内存复制操作延迟到父进程或子进程向某内存页面写入数据之前，在只读访问的情况下父进程和子进程可以共用同一内存页。\n例如，使用fork的一种可能的情况是，用户打开另一个浏览器窗口。如果选中了对应的选项，浏览器将执行fork，复制其代码，接下来子进程中将启动适当的操作建立新窗口。\n(2) exec将一个新程序加载到当前进程的内存中并执行。旧程序的内存页将刷出，其内容将替换为新的数据。然后开始执行新程序。\n4.内核的特别性 # 5.行文注记 # 6.小结 # ","date":"16 July 2023","permalink":"/linux/book/kernel01/","section":"Linuxes","summary":"最近计划学习 Linux 内核相关内容，Professional Linux Kernel Architecture","title":"深入 Linux 内核架构 01"},{"content":"终于在这个周日的晚上，把这个博客搭建完成了，希望之后可以养成写博客的习惯\n","date":"16 July 2023","permalink":"/diary/day01/","section":"Diaries","summary":"终于在这个周日的晚上，把这个博客搭建完成了，希望之后可以养成写博客的习惯","title":"2023年7月16日"},{"content":"","date":"16 July 2023","permalink":"/tags/diary/","section":"Tags","summary":"","title":"Diary"},{"content":" This is title # 这个包比较简单，就是将文件进行打包和解包，要是熟悉 Linux 下的 tar 命令这个就很好理解了。 主要是通过 tar.Reader 读取 tar 包，通过 tar.Writer 写入 tar 包，在写入的过程中再设置一下头，详细的过程以示例的方式进行展示，可以查看代码里面的注释。\n参考：\n标准库 tar 中文文档\n标准库 tar 官方文档\n单个文件操作 # 这个非常简单，就是读取一个文件，进行打包及解包操作即可。\n单个文件打包 # 从 /etc/passwd 下复制了一个 passwd 文件到当前目录下，用来做压缩测试。什么文件都是可以的，自己随意写一个也行。这里的示例主要为了说明 tar ，没有处理路径，所以过程全部假设是在当前目录下执行。\ncp /etc/passwd . 关于文件的打包直接查看示例代码，已经在示例代码中做了详细的注释。\n示例代码（ pack_single_file.go ）：\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;log\u0026#34; \u0026#34;archive/tar\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; ) func main() { // 准备打包的源文件 var srcFile = \u0026#34;passwd\u0026#34; // 打包后的文件 var desFile = fmt.Sprintf(\u0026#34;%s.tar\u0026#34;,srcFile) // 需要注意文件的打开即关闭的顺序，因为 defer 是后入先出，所以关闭顺序很重要 // 第一次写这个示例的时候就没注意，导致写完的 tar 包不完整 // ###### 第 1 步，先准备好一个 tar.Writer 结构，然后再向里面写入内容。 ###### // 创建一个文件，用来保存打包后的 passwd.tar 文件 fw, err := os.Create(desFile) ErrPrintln(err) defer fw.Close() // 通过 fw 创建一个 tar.Writer tw := tar.NewWriter(fw) // 这里不要忘记关闭，如果不能成功关闭会造成 tar 包不完整 // 所以这里在关闭的同时进行判断，可以清楚的知道是否成功关闭 defer func() { if err := tw.Close(); err != nil { ErrPrintln(err) } }() // ###### 第 2 步，处理文件信息，也就是 tar.Header 相关的 ###### // tar 包共有两部分内容：文件信息和文件数据 // 通过 Stat 获取 FileInfo，然后通过 FileInfoHeader 得到 hdr tar.*Header fi, err := os.Stat(srcFile) ErrPrintln(err) hdr, err := tar.FileInfoHeader(fi, \u0026#34;\u0026#34;) // 将 tar 的文件信息 hdr 写入到 tw err = tw.WriteHeader(hdr) ErrPrintln(err) // 将文件数据写入 // 打开准备写入的文件 fr, err := os.Open(srcFile) ErrPrintln(err) defer fr.Close() written, err := io.Copy(tw, fr) ErrPrintln(err) log.Printf(\u0026#34;共写入了 %d 个字符的数据\\n\u0026#34;,written) } // 定义一个用来打印的函数，少写点代码，因为要处理很多次的 err // 后面其他示例还会继续使用这个函数，就不单独再写，望看到此函数了解 func ErrPrintln(err error) { if err != nil { log.Println(err) os.Exit(1) } } 单个文件解包 # 这个也很简单，基本上将上面过程反过来，只需要处理 tar.Reader 即可，详细的描述见示例。\n这里就用刚刚打包的 passwd.tar 文件做示例，如果怕结果看不出效果，可以将之前用的 passwd 源文件删除。\nrm passwd 示例代码（ unpack_single_file.go ）：\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;archive/tar\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; ) func main() { var srcFile = \u0026#34;passwd.tar\u0026#34; // 将 tar 包打开 fr, err := os.Open(srcFile) ErrPrintln(err) defer fr.Close() // 通过 fr 创建一个 tar.*Reader 结构，然后将 tr 遍历，并将数据保存到磁盘中 tr := tar.NewReader(fr) for hdr, err := tr.Next(); err != io.EOF; hdr, err = tr.Next(){ // 处理 err ！= nil 的情况 ErrPrintln(err) // 获取文件信息 fi := hdr.FileInfo() // 创建一个空文件，用来写入解包后的数据 fw, err := os.Create(fi.Name()) ErrPrintln(err) // 将 tr 写入到 fw n, err := io.Copy(fw, tr) ErrPrintln(err) log.Printf(\u0026#34;解包： %s 到 %s ，共处理了 %d 个字符的数据。\u0026#34;, srcFile,fi.Name(),n) // 设置文件权限，这样可以保证和原始文件权限相同，如果不设置，会根据当前系统的 umask 来设置。 os.Chmod(fi.Name(),fi.Mode().Perm()) // 注意，因为是在循环中，所以就没有使用 defer 关闭文件 // 如果想使用 defer 的话，可以将文件写入的步骤单独封装在一个函数中即可 fw.Close() } } func ErrPrintln(err error){ if err != nil { log.Fatalln(err) os.Exit(1) } } 操作整个目录 # 我们实际中 tar 很少会去打包单个文件，一般都是打包整个目录，并且打包的时候通过 gzip 或者 bzip2 压缩。\n如果要打包整个目录，可以通过递归的方式来实现。这里只演示了 gzip 方式压缩，这个实现非常简单，只需要在 fw 和 tw 之前加上一层压缩即可，详情见示例代码。\n为了测试打包整个目录，复制了一个 log 目录到当前路径下。什么目录和文件都可以，只是因为这个里面内容比较多，就拿这个来做测试了。\n# 出现没有权限的错误不用管它，复制过来多少是多少吧 cp -r /var/log/ . 详细的操作会在注释中说明，不过在之前单文件中出现过的步骤不再注释。\n打包压缩 # 示例代码（ targz.go ）：\npackage main import ( \u0026#34;archive/tar\u0026#34; \u0026#34;compress/gzip\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // 修改日志格式，显示出错代码的所在行，方便调试，实际项目中一般不记录这个。 var src = \u0026#34;apt\u0026#34; var dst = fmt.Sprintf(\u0026#34;%s.tar.gz\u0026#34;, src) // 将步骤写入了一个函数中，这样处理错误方便一些 if err := Tar(src, dst); err != nil { log.Fatalln(err) } } func Tar(src, dst string) (err error) { // 创建文件 fw, err := os.Create(dst) if err != nil { return } defer fw.Close() // 将 tar 包使用 gzip 压缩，其实添加压缩功能很简单， // 只需要在 fw 和 tw 之前加上一层压缩就行了，和 Linux 的管道的感觉类似 gw := gzip.NewWriter(fw) defer gw.Close() // 创建 Tar.Writer 结构 tw := tar.NewWriter(gw) // 如果需要启用 gzip 将上面代码注释，换成下面的 defer tw.Close() // 下面就该开始处理数据了，这里的思路就是递归处理目录及目录下的所有文件和目录 // 这里可以自己写个递归来处理，不过 Golang 提供了 filepath.Walk 函数，可以很方便的做这个事情 // 直接将这个函数的处理结果返回就行，需要传给它一个源文件或目录，它就可以自己去处理 // 我们就只需要去实现我们自己的 打包逻辑即可，不需要再去路径相关的事情 return filepath.Walk(src, func(fileName string, fi os.FileInfo, err error) error { // 因为这个闭包会返回个 error ，所以先要处理一下这个 if err != nil { return err } // 这里就不需要我们自己再 os.Stat 了，它已经做好了，我们直接使用 fi 即可 hdr, err := tar.FileInfoHeader(fi, \u0026#34;\u0026#34;) if err != nil { return err } // 这里需要处理下 hdr 中的 Name，因为默认文件的名字是不带路径的， // 打包之后所有文件就会堆在一起，这样就破坏了原本的目录结果 // 例如： 将原本 hdr.Name 的 syslog 替换程 log/syslog // 这个其实也很简单，回调函数的 fileName 字段给我们返回来的就是完整路径的 log/syslog // strings.TrimPrefix 将 fileName 的最左侧的 / 去掉， // 熟悉 Linux 的都知道为什么要去掉这个 hdr.Name = strings.TrimPrefix(fileName, string(filepath.Separator)) // 写入文件信息 if err := tw.WriteHeader(hdr); err != nil { return err } // 判断下文件是否是标准文件，如果不是就不处理了， // 如： 目录，这里就只记录了文件信息，不会执行下面的 copy if !fi.Mode().IsRegular() { return nil } // 打开文件 fr, err := os.Open(fileName) defer fr.Close() if err != nil { return err } // copy 文件数据到 tw n, err := io.Copy(tw, fr) if err != nil { return err } // 记录下过程，这个可以不记录，这个看需要，这样可以看到打包的过程 log.Printf(\u0026#34;成功打包 %s ，共写入了 %d 字节的数据\\n\u0026#34;, fileName, n) return nil }) } 打包及压缩就搞定了，不过这个代码现在我还发现有个问题，就是不能处理软链接\n解包解压 # 这个过程基本就是把压缩的过程返回来，多了些创建目录的操作\npackage main import ( \u0026#34;archive/tar\u0026#34; \u0026#34;compress/gzip\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; ) func main() { var dst = \u0026#34;\u0026#34; // 不写就是解压到当前目录 var src = \u0026#34;log.tar.gz\u0026#34; UnTar(dst, src) } func UnTar(dst, src string) (err error) { // 打开准备解压的 tar 包 fr, err := os.Open(src) if err != nil { return } defer fr.Close() // 将打开的文件先解压 gr, err := gzip.NewReader(fr) if err != nil { return } defer gr.Close() // 通过 gr 创建 tar.Reader tr := tar.NewReader(gr) // 现在已经获得了 tar.Reader 结构了，只需要循环里面的数据写入文件就可以了 for { hdr, err := tr.Next() switch { case err == io.EOF: return nil case err != nil: return err case hdr == nil: continue } // 处理下保存路径，将要保存的目录加上 header 中的 Name // 这个变量保存的有可能是目录，有可能是文件，所以就叫 FileDir 了…… dstFileDir := filepath.Join(dst, hdr.Name) // 根据 header 的 Typeflag 字段，判断文件的类型 switch hdr.Typeflag { case tar.TypeDir: // 如果是目录时候，创建目录 // 判断下目录是否存在，不存在就创建 if b := ExistDir(dstFileDir); !b { // 使用 MkdirAll 不使用 Mkdir ，就类似 Linux 终端下的 mkdir -p， // 可以递归创建每一级目录 if err := os.MkdirAll(dstFileDir, 0775); err != nil { return err } } case tar.TypeReg: // 如果是文件就写入到磁盘 // 创建一个可以读写的文件，权限就使用 header 中记录的权限 // 因为操作系统的 FileMode 是 int32 类型的，hdr 中的是 int64，所以转换下 file, err := os.OpenFile(dstFileDir, os.O_CREATE|os.O_RDWR, os.FileMode(hdr.Mode)) if err != nil { return err } n, err := io.Copy(file, tr) if err != nil { return err } // 将解压结果输出显示 fmt.Printf(\u0026#34;成功解压： %s , 共处理了 %d 个字符\\n\u0026#34;, dstFileDir, n) // 不要忘记关闭打开的文件，因为它是在 for 循环中，不能使用 defer // 如果想使用 defer 就放在一个单独的函数中 file.Close() } } return nil } // 判断目录是否存在 func ExistDir(dirname string) bool { fi, err := os.Stat(dirname) return (err == nil || os.IsExist(err)) \u0026amp;\u0026amp; fi.IsDir() } 到这里解压就完成了，只是一个实验代码，还有很多不完善的地方，欢迎提出宝贵的意见。\n","date":"15 July 2023","permalink":"/python/tests/","section":"Pythons","summary":"This is title # 这个包比较简单，就是将文件进行打包和解包，要是熟悉 Linux 下的 tar 命令这个就很好理解了。 主要是通过 tar.","title":"First Blog"},{"content":"全文目录\n1.IO 多路复用 # 1.1 IO 多路复用解释 # 首先拆解多路复用一词：\n多路：存在多个待服务的对象 复用：只由一个执行单元提供服务 串联上述要点，多路复用指的是，由一个执行单元，同时对多个对象提供服务，形成一对多的服务关系\n打个比方：多名顾客在餐厅内用餐，考虑到经营成本，很难做到为每名顾客单独提供一名招待员作一对一服务，因此餐厅经理安排每名服务生固定负责几个餐桌，服务生在几个桌次间来回辗转提供服务，这个过程本质上就是一种多路复用\n在 linux 操作系统中，对 IO 多路复用的概念有着更加明确的定义：\n多路：存在多个需要处理 io event 的 fd（linux 中，一切皆文件，所有事物均可抽象为一个文件句柄 file descriptor，简称 fd） 复用：复用一个 loop thread 同时为多个 fd 提供处理服务（线程 thread 是内核视角下的最小调度单位；多路复用通常为循环模型 loop model，因此称为 loop thread） IO 多路复用中，loop thread 是提供服务的乙方；待处理 io event 的 fd 们是甲方。本着顾客是上帝的原则，乙方有义务为甲方提供更优质的服务，这里的服务质量就体现在一句话：”随叫随到，别让老板等久了”\n在餐厅顾客没有需求的时候，服务生趁着闲工夫摸个鱼打个盹也尚无不可。但是一旦顾客招呼时，服务生需要第一时间赶到对需求作出响应\n此外，由于服务生和顾客之间的服务关系是一对多，所以还要考虑到有多名顾客同时招呼时，服务生如何作兼容处理，让每名顾客都不至于产生被冷落的感觉。这是一门学问，也同样是计算机领域 IO 多路复用场景下需要解决的问题\n1.2 多路复用简单实现 # 1.2.1 阻塞 IO # 通过一段伪代码，来尝试让 IO 多路复用这个概念看起来更加具体一些：\n// 多个待服务的 fd fds = [fd1,fd2,fd3,...] // 遍历 fd 列表，末尾和首部相连，形成循环 i = 0 for { // 获取本轮待处理的 fd fd = fds[i] // 从 fd 中读数据 data = read(fd) // 处理数据 handle(data) // 推进遍历 i++ if i == len(fds){ i = 0 } } 上述搭了个架子，核心分为几步：\n定义了待处理的 fds 列表（多路） 循环遍历 fds 列表，每轮负责读一个 fd（复用） 这是个乞丐版的 IO 多路复用模型看起来似乎有那么点意思了. 然而其本质上是一种阻塞 IO 模型（Blocking IO，简称 BIO）. 事实上，上述实现存在一个致命的问题，那就是句柄 fd 默认的 io 操作是阻塞型的，因此倘若在读 fd1 的时候，io event 没到达，那么 loop thread 就会陷入阻塞，后续 fd2、fd3 哪怕有 io event 到达，也无法得到执行\n上述问题翻译成更形象的场景，大概就是：\nA桌顾客对服务生说，你先搁这候着，我看会儿菜单，一会点菜\n服务生于是站定A桌，打定主意在A桌点完菜之后再离开\n在此期间，服务生辖区内的B桌、C桌招呼有事，服务生也充耳不闻，只等A桌事情完结才肯挪动步子\n这样的服务显然不够到位，倘若人人如此，餐厅必然面临倒闭\n1.2.2 非阻塞 IO # 基于 BIO 存在的问题，我们进行一轮改进，核心是将 read 操作由同步阻塞操作改为带有尝试性的非阻塞操作。在读一个 fd 的时候，倘若 io event 已就绪就正常读取，否则就即时返回并抛出一个特定类型的错误，让 loop thread 能够正常执行下去，为其他 fd 提供服务\n// 多个待服务的 fd fds = [fd1,fd2,fd3,...] // 遍历 fd 列表，末尾和首部相连，形成循环 i = 0 for { // 获取本轮待处理的 fd fd = fds[i] // 尝试从 fd 中读数据，失败时不阻塞，而是抛出错误 data,err = tryRead(fd) // 读取数据成功，处理数据 if err == nil{ handle(data) } // 小睡一秒后再推进流程 sleep(1 second) // 推进遍历 i++ if i == len(fds){ i = 0 } } 上述伪代码核心步骤如下：\n定义了待处理的 fds 列表 遍历 fds 列表，每轮尝试从一个 fd 中读数据 倘若 io event 已就绪，则正常处理结果 倘若 io event 未就绪，只抛出错误，同样不阻塞流程 小睡一会儿，然后继续推进流程 这里确实解决阻塞 IO 中的问题，其本质上是一种非阻塞 IO 模型（Nonblocking IO，简称 NIO），但这里仍然存在问题，就是每轮处理之间的休眠时间。倘若在休眠期间，fd 中有 io event 到达，就无法被正常处理，这同样是一种不好的体验\n这一问题翻译成餐厅的场景，指的就是服务生每次主动问询或者为一名客人提供服务后，就要大喘气休息几分钟，期间对客人不管不顾，这样的服务态度客人同样不会买账\n那大家可能会问了，倘若把此处的休眠操作去除了如何？\n答案是同样有问题. 倘若不限制轮询的执行频率，那么不轮 fd 中是否有 io event，程序都会一直高强度运行，这会导致 CPU 空转，造成很大程度的资源浪费\n用餐厅的场景来聊，指的是餐厅招了个视听都不好的服务生，他感应不到客人的召唤，需要时时刻刻奔走在各个餐桌之间主动去询问客人们是否需要服务。这种情况下，哪怕客人们性子好不嫌烦，服务生自己也被这种高强度的反复横跳动作给累坏了\n那大家可能又问了. 餐厅就不能招个正常的服务生吗，让他在听到客人的招呼时就去提供服务，否则就在一边老实歇着\n没错，这就是正解，设计程序的码农们也是这么想的. 然而实际情况很悲催，在用户态视角下的程序正是哪一个耳目昏聩的服务生，对于 io event 的到达并没有能力做到准确地把握\n于是，这就需要引入操作系统内核的帮助，通过几个内核对外暴露的接口，来进行 IO 多路复用的优雅实现，做到真正意义上的“随叫随到”\n1.3 IO 多路复用的优雅实现 # linux 内核提供了三种经典的多路复用技术：\n从上图中可以看到，各个技术之间通过单向箭头连接，因此是一个持续演化改进的过程，select 最通用，但是相对粗糙；而 epoll 则最精致，在性能上也有着最优越的表现\npoll 在 select 的基础之上做了改进，但治标不治本，优化得不够彻底. 我们核心还是来对比看看 select 和 epoll 之间的共性和差异：\n（1）select\n一次可以处理多个 fd，体现多路，但 fd 数量有限，最多 1024 个 loop thread 通过 select 将一组 fd 提交到内核做监听 当 fd 中无 io event 就绪时，loop thread 会陷入阻塞 每当这组 fd 中有 io event 到达时，内核会唤醒 loop thread loop thread 无法精准感知到哪些 fd 就绪，需要遍历一轮 fd 列表，时间复杂度 O(N) 托付给内核的 fd 列表只具有一轮交互的时效，新的轮次中，loop thread 需要重新将监听的 fd 列表再传递给内核一次 （2）epoll\n每次处理的 fd 数量无上限 loop thread 通过 epoll_create 操作创建一个 epoll 池子 loop thread 通过 epoll_ctl 每次将一个待监听的 fd 添加到 epoll 池中 每当 fd 列表中有 fd 就绪事件到达时，会唤醒 loop thread，同时内核会将处于就绪态的 fd 直接告知 loop thread，无需额外遍历 综上所述，select 和 epoll 等多路复用操作利用了内核的能力，能在待监听 fd 中有 io event 到达时，将 loop thread 唤醒，避免无意义的主动轮询操作\n其中，epoll 相比于 select 的核心性能优势在于：\nloop thread 被唤醒时，能明确知道哪些 fd 需要处理，减少了一次额外遍历的操作，时间复杂度由 O(N) 优化到 O(1) epoll 通过将创建池子和添加 fd 两个操作解耦，实现了池中 fd 数据的复用，减少了用户态与内核态间的数据拷贝成本 2.EventPoll 原理 # 2.1 核心指令 # epoll 又称 EventPoll，使用很简单，包含三个指令：\nepoll_create epoll_ctl epoll_wait 未完待续\u0026hellip;\n","date":"15 July 2023","permalink":"/golang/learn/epoll/","section":"Golangs","summary":"全文目录","title":"Go 网络 IO 模型之 EPOLL"},{"content":"Go 面经 相关记录\n基础语法 # = 和 := 的区别？ =是赋值变量，:=是定义变量 指针的作用 一个指针可以指向任意变量的地址，它所指向的地址在32位或64位机器上分别固定占4或8个字节。指针的作用有 获取变量的值 改变变量的值 用指针替代值传入函数，比如类的接收器就是这样的 Go 允许多个返回值吗？ 可以。通常函数除了一般返回值还会返回一个error Go 有异常类型吗？ 有。Go用error类型代替try\u0026hellip;catch语句，这样可以节省资源。同时增加代码可读性 也可以用errors.New()来定义自己的异常。errors.Error()会返回异常的字符串表示。只要实现error接口就可以定义自己的异常， 什么是协程（Goroutine） *协程是用户态轻量级线程，它是线程调度的基本单位。通常在函数前加上go关键字就能实现并发。一个Goroutine会以一个很小的栈启动2KB或4KB，当遇到栈空间不足时，栈会自动伸缩， 因此可以轻易实现成千上万个goroutine同时启动 如何高效地拼接字符串 拼接字符串的方式有：+ , fmt.Sprintf , strings.Builder, bytes.Buffer, strings.Join 使用+操作符进行拼接时，会对字符串进行遍历，计算并开辟一个新的空间来存储原来的两个字符串由于采用了接口参数，必须要用反射获取值，因此有性能损耗 用WriteString()进行拼接，内部实现是指针+切片，同时String()返回拼接后的字符串，它是直接把[]byte转换为string，从而避免变量拷贝 bytes.Buffer是一个一个缓冲byte类型的缓冲器，这个缓冲器里存放着都是byte,bytes.buffer底层也是一个[]byte切片 strings.join也是基于strings.builder来实现的,并且可以自定义分隔符，在join方法内调用了b.Grow(n)方法，这个是进行初步的容量分配，而前面计算的n的长度就是我们要拼接的slice的长度，因为我们传入切片长度固定，所以提前进行容量分配可以减少内存分配，很高效 性能比较：strings.Join ≈ strings.Builder \u0026gt; bytes.Buffer \u0026gt; \u0026ldquo;+\u0026rdquo; \u0026gt; fmt.Sprintf 什么是 rune 类型 如何判断 map 中是否包含某个 key ？ Go 支持默认参数或可选参数吗？ defer 的执行顺序 如何交换 2 个变量的值？ Go 语言 tag 的用处？ 如何判断 2 个字符串切片（slice) 是相等的？ 字符串打印时，%v 和 %+v 的区别 Go 语言中如何表示枚举值(enums)？ 空 struct{} 的用途 实现原理 # init() 函数是什么时候执行的 Go 语言的局部变量分配在栈上还是堆上？ 2 个 interface 可以比较吗 ？ 2 个 nil 可能不相等吗？ 简述 Go 语言GC(垃圾回收)的工作原理 函数返回局部变量的指针是否安全？ 非接口非接口的任意类型 T() 都能够调用 *T 的方法吗？反过来呢？ 并发编程 # 无缓冲的 channel 和有缓冲的 channel 的区别？ 什么是协程泄露(Goroutine Leak)？ Go 可以限制运行时操作系统线程的数量吗？ 代码输出 # 变量与常量 作用域 defer 延迟调用 ","date":"15 July 2023","permalink":"/golang/interview/problems/","section":"Golangs","summary":"Go 面经 相关记录","title":"Go 面经"},{"content":"","date":"15 July 2023","permalink":"/tags/learn/","section":"Tags","summary":"","title":"Learn"},{"content":" This is title # 这个包比较简单，就是将文件进行打包和解包，要是熟悉 Linux 下的 tar 命令这个就很好理解了。 主要是通过 tar.Reader 读取 tar 包，通过 tar.Writer 写入 tar 包，在写入的过程中再设置一下头，详细的过程以示例的方式进行展示，可以查看代码里面的注释。\n参考：\n标准库 tar 中文文档\n标准库 tar 官方文档\n单个文件操作 # 这个非常简单，就是读取一个文件，进行打包及解包操作即可。\n单个文件打包 # 从 /etc/passwd 下复制了一个 passwd 文件到当前目录下，用来做压缩测试。什么文件都是可以的，自己随意写一个也行。这里的示例主要为了说明 tar ，没有处理路径，所以过程全部假设是在当前目录下执行。\ncp /etc/passwd . 关于文件的打包直接查看示例代码，已经在示例代码中做了详细的注释。\n示例代码（ pack_single_file.go ）：\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;log\u0026#34; \u0026#34;archive/tar\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; ) func main() { // 准备打包的源文件 var srcFile = \u0026#34;passwd\u0026#34; // 打包后的文件 var desFile = fmt.Sprintf(\u0026#34;%s.tar\u0026#34;,srcFile) // 需要注意文件的打开即关闭的顺序，因为 defer 是后入先出，所以关闭顺序很重要 // 第一次写这个示例的时候就没注意，导致写完的 tar 包不完整 // ###### 第 1 步，先准备好一个 tar.Writer 结构，然后再向里面写入内容。 ###### // 创建一个文件，用来保存打包后的 passwd.tar 文件 fw, err := os.Create(desFile) ErrPrintln(err) defer fw.Close() // 通过 fw 创建一个 tar.Writer tw := tar.NewWriter(fw) // 这里不要忘记关闭，如果不能成功关闭会造成 tar 包不完整 // 所以这里在关闭的同时进行判断，可以清楚的知道是否成功关闭 defer func() { if err := tw.Close(); err != nil { ErrPrintln(err) } }() // ###### 第 2 步，处理文件信息，也就是 tar.Header 相关的 ###### // tar 包共有两部分内容：文件信息和文件数据 // 通过 Stat 获取 FileInfo，然后通过 FileInfoHeader 得到 hdr tar.*Header fi, err := os.Stat(srcFile) ErrPrintln(err) hdr, err := tar.FileInfoHeader(fi, \u0026#34;\u0026#34;) // 将 tar 的文件信息 hdr 写入到 tw err = tw.WriteHeader(hdr) ErrPrintln(err) // 将文件数据写入 // 打开准备写入的文件 fr, err := os.Open(srcFile) ErrPrintln(err) defer fr.Close() written, err := io.Copy(tw, fr) ErrPrintln(err) log.Printf(\u0026#34;共写入了 %d 个字符的数据\\n\u0026#34;,written) } // 定义一个用来打印的函数，少写点代码，因为要处理很多次的 err // 后面其他示例还会继续使用这个函数，就不单独再写，望看到此函数了解 func ErrPrintln(err error) { if err != nil { log.Println(err) os.Exit(1) } } 单个文件解包 # 这个也很简单，基本上将上面过程反过来，只需要处理 tar.Reader 即可，详细的描述见示例。\n这里就用刚刚打包的 passwd.tar 文件做示例，如果怕结果看不出效果，可以将之前用的 passwd 源文件删除。\nrm passwd 示例代码（ unpack_single_file.go ）：\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;archive/tar\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; ) func main() { var srcFile = \u0026#34;passwd.tar\u0026#34; // 将 tar 包打开 fr, err := os.Open(srcFile) ErrPrintln(err) defer fr.Close() // 通过 fr 创建一个 tar.*Reader 结构，然后将 tr 遍历，并将数据保存到磁盘中 tr := tar.NewReader(fr) for hdr, err := tr.Next(); err != io.EOF; hdr, err = tr.Next(){ // 处理 err ！= nil 的情况 ErrPrintln(err) // 获取文件信息 fi := hdr.FileInfo() // 创建一个空文件，用来写入解包后的数据 fw, err := os.Create(fi.Name()) ErrPrintln(err) // 将 tr 写入到 fw n, err := io.Copy(fw, tr) ErrPrintln(err) log.Printf(\u0026#34;解包： %s 到 %s ，共处理了 %d 个字符的数据。\u0026#34;, srcFile,fi.Name(),n) // 设置文件权限，这样可以保证和原始文件权限相同，如果不设置，会根据当前系统的 umask 来设置。 os.Chmod(fi.Name(),fi.Mode().Perm()) // 注意，因为是在循环中，所以就没有使用 defer 关闭文件 // 如果想使用 defer 的话，可以将文件写入的步骤单独封装在一个函数中即可 fw.Close() } } func ErrPrintln(err error){ if err != nil { log.Fatalln(err) os.Exit(1) } } 操作整个目录 # 我们实际中 tar 很少会去打包单个文件，一般都是打包整个目录，并且打包的时候通过 gzip 或者 bzip2 压缩。\n如果要打包整个目录，可以通过递归的方式来实现。这里只演示了 gzip 方式压缩，这个实现非常简单，只需要在 fw 和 tw 之前加上一层压缩即可，详情见示例代码。\n为了测试打包整个目录，复制了一个 log 目录到当前路径下。什么目录和文件都可以，只是因为这个里面内容比较多，就拿这个来做测试了。\n# 出现没有权限的错误不用管它，复制过来多少是多少吧 cp -r /var/log/ . 详细的操作会在注释中说明，不过在之前单文件中出现过的步骤不再注释。\n打包压缩 # 示例代码（ targz.go ）：\npackage main import ( \u0026#34;archive/tar\u0026#34; \u0026#34;compress/gzip\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // 修改日志格式，显示出错代码的所在行，方便调试，实际项目中一般不记录这个。 var src = \u0026#34;apt\u0026#34; var dst = fmt.Sprintf(\u0026#34;%s.tar.gz\u0026#34;, src) // 将步骤写入了一个函数中，这样处理错误方便一些 if err := Tar(src, dst); err != nil { log.Fatalln(err) } } func Tar(src, dst string) (err error) { // 创建文件 fw, err := os.Create(dst) if err != nil { return } defer fw.Close() // 将 tar 包使用 gzip 压缩，其实添加压缩功能很简单， // 只需要在 fw 和 tw 之前加上一层压缩就行了，和 Linux 的管道的感觉类似 gw := gzip.NewWriter(fw) defer gw.Close() // 创建 Tar.Writer 结构 tw := tar.NewWriter(gw) // 如果需要启用 gzip 将上面代码注释，换成下面的 defer tw.Close() // 下面就该开始处理数据了，这里的思路就是递归处理目录及目录下的所有文件和目录 // 这里可以自己写个递归来处理，不过 Golang 提供了 filepath.Walk 函数，可以很方便的做这个事情 // 直接将这个函数的处理结果返回就行，需要传给它一个源文件或目录，它就可以自己去处理 // 我们就只需要去实现我们自己的 打包逻辑即可，不需要再去路径相关的事情 return filepath.Walk(src, func(fileName string, fi os.FileInfo, err error) error { // 因为这个闭包会返回个 error ，所以先要处理一下这个 if err != nil { return err } // 这里就不需要我们自己再 os.Stat 了，它已经做好了，我们直接使用 fi 即可 hdr, err := tar.FileInfoHeader(fi, \u0026#34;\u0026#34;) if err != nil { return err } // 这里需要处理下 hdr 中的 Name，因为默认文件的名字是不带路径的， // 打包之后所有文件就会堆在一起，这样就破坏了原本的目录结果 // 例如： 将原本 hdr.Name 的 syslog 替换程 log/syslog // 这个其实也很简单，回调函数的 fileName 字段给我们返回来的就是完整路径的 log/syslog // strings.TrimPrefix 将 fileName 的最左侧的 / 去掉， // 熟悉 Linux 的都知道为什么要去掉这个 hdr.Name = strings.TrimPrefix(fileName, string(filepath.Separator)) // 写入文件信息 if err := tw.WriteHeader(hdr); err != nil { return err } // 判断下文件是否是标准文件，如果不是就不处理了， // 如： 目录，这里就只记录了文件信息，不会执行下面的 copy if !fi.Mode().IsRegular() { return nil } // 打开文件 fr, err := os.Open(fileName) defer fr.Close() if err != nil { return err } // copy 文件数据到 tw n, err := io.Copy(tw, fr) if err != nil { return err } // 记录下过程，这个可以不记录，这个看需要，这样可以看到打包的过程 log.Printf(\u0026#34;成功打包 %s ，共写入了 %d 字节的数据\\n\u0026#34;, fileName, n) return nil }) } 打包及压缩就搞定了，不过这个代码现在我还发现有个问题，就是不能处理软链接\n解包解压 # 这个过程基本就是把压缩的过程返回来，多了些创建目录的操作\npackage main import ( \u0026#34;archive/tar\u0026#34; \u0026#34;compress/gzip\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; ) func main() { var dst = \u0026#34;\u0026#34; // 不写就是解压到当前目录 var src = \u0026#34;log.tar.gz\u0026#34; UnTar(dst, src) } func UnTar(dst, src string) (err error) { // 打开准备解压的 tar 包 fr, err := os.Open(src) if err != nil { return } defer fr.Close() // 将打开的文件先解压 gr, err := gzip.NewReader(fr) if err != nil { return } defer gr.Close() // 通过 gr 创建 tar.Reader tr := tar.NewReader(gr) // 现在已经获得了 tar.Reader 结构了，只需要循环里面的数据写入文件就可以了 for { hdr, err := tr.Next() switch { case err == io.EOF: return nil case err != nil: return err case hdr == nil: continue } // 处理下保存路径，将要保存的目录加上 header 中的 Name // 这个变量保存的有可能是目录，有可能是文件，所以就叫 FileDir 了…… dstFileDir := filepath.Join(dst, hdr.Name) // 根据 header 的 Typeflag 字段，判断文件的类型 switch hdr.Typeflag { case tar.TypeDir: // 如果是目录时候，创建目录 // 判断下目录是否存在，不存在就创建 if b := ExistDir(dstFileDir); !b { // 使用 MkdirAll 不使用 Mkdir ，就类似 Linux 终端下的 mkdir -p， // 可以递归创建每一级目录 if err := os.MkdirAll(dstFileDir, 0775); err != nil { return err } } case tar.TypeReg: // 如果是文件就写入到磁盘 // 创建一个可以读写的文件，权限就使用 header 中记录的权限 // 因为操作系统的 FileMode 是 int32 类型的，hdr 中的是 int64，所以转换下 file, err := os.OpenFile(dstFileDir, os.O_CREATE|os.O_RDWR, os.FileMode(hdr.Mode)) if err != nil { return err } n, err := io.Copy(file, tr) if err != nil { return err } // 将解压结果输出显示 fmt.Printf(\u0026#34;成功解压： %s , 共处理了 %d 个字符\\n\u0026#34;, dstFileDir, n) // 不要忘记关闭打开的文件，因为它是在 for 循环中，不能使用 defer // 如果想使用 defer 就放在一个单独的函数中 file.Close() } } return nil } // 判断目录是否存在 func ExistDir(dirname string) bool { fi, err := os.Stat(dirname) return (err == nil || os.IsExist(err)) \u0026amp;\u0026amp; fi.IsDir() } 到这里解压就完成了，只是一个实验代码，还有很多不完善的地方，欢迎提出宝贵的意见。\n","date":"15 July 2023","permalink":"/python/python-blog/","section":"Pythons","summary":"This is title # 这个包比较简单，就是将文件进行打包和解包，要是熟悉 Linux 下的 tar 命令这个就很好理解了。 主要是通过 tar.","title":"Python 博客第一篇"},{"content":"","date":"15 July 2023","permalink":"/python/","section":"Pythons","summary":"","title":"Pythons"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"1 January 0001","permalink":"/series/","section":"Series","summary":"","title":"Series"}]